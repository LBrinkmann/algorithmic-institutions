{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cb4aef8",
   "metadata": {
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "n_contributions = 21\n",
    "n_punishments = 31\n",
    "n_cross_val = 2\n",
    "fraction_training = 0.1\n",
    "data_file = \"../../data/experiments/pilot_random1_player_round_slim.csv\"\n",
    "output_path = \"../../data/training/dev\"\n",
    "labels = {}\n",
    "model_name = \"graph\"\n",
    "model_args = {\n",
    "    \"add_rnn\": False,\n",
    "    \"add_edge_model\": False,\n",
    "    \"add_global_model\": False,\n",
    "    \"hidden_size\": 10,\n",
    "    \"x_encoding\": [\n",
    "        {\"name\": \"prev_contributions\", \"n_levels\": 21, \"encoding\": \"numeric\"},\n",
    "        {\"name\": \"prev_punishments\", \"n_levels\": 31, \"encoding\": \"numeric\"},\n",
    "        {\"name\": \"round_number\", \"n_levels\": 16, \"encoding\": \"numeric\"},\n",
    "        {\"name\": \"prev_common_good\", \"norm\": 128, \"etype\": \"float\"},\n",
    "        {\"name\": \"prev_valid\", \"etype\": \"bool\"},\n",
    "    ],\n",
    "    \"u_encoding\": [{\"name\": \"prev_common_good\", \"norm\": 128, \"etype\": \"float\"}],\n",
    "}\n",
    "optimizer_args = {\"lr\": 0.001, \"weight_decay\": 1e-05}\n",
    "train_args = {\"epochs\": 1000, \"batch_size\": 20, \"clamp_grad\": 1, \"eval_period\": 10}\n",
    "shuffle_features = ['prev_punishments', 'prev_contributions', 'prev_common_good']\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44582683",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-19T16:41:27.956497Z",
     "iopub.status.busy": "2022-04-19T16:41:27.956108Z",
     "iopub.status.idle": "2022-04-19T16:41:30.638413Z",
     "shell.execute_reply": "2022-04-19T16:41:30.637779Z"
    },
    "papermill": {
     "duration": 2.691081,
     "end_time": "2022-04-19T16:41:30.640419",
     "exception": false,
     "start_time": "2022-04-19T16:41:27.949338",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mpib/brinkmann/repros/algorithmic-institutions/.venv/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/mpib/brinkmann/repros/algorithmic-institutions/.venv/lib/python3.9/site-packages/torch/cuda/__init__.py:82: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 10010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:112.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch as th\n",
    "from aimanager.generic.data import create_syn_data, create_torch_data, get_cross_validations\n",
    "from aimanager.artificial_humans import AH_MODELS\n",
    "from aimanager.artificial_humans.evaluation import Evaluator\n",
    "from aimanager.utils.array_to_df import using_multiindex\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "output_path = os.path.join(output_path, 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6659c46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-15T16:13:44.221298Z",
     "iopub.status.busy": "2022-02-15T16:13:44.220802Z",
     "iopub.status.idle": "2022-02-15T16:13:44.264216Z",
     "shell.execute_reply": "2022-02-15T16:13:44.263653Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_file)\n",
    "\n",
    "data = create_torch_data(df)\n",
    "syn_data = create_syn_data(n_contribution=21, n_punishment=31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f144b88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-15T16:13:44.354450Z",
     "iopub.status.busy": "2022-02-15T16:13:44.354021Z",
     "iopub.status.idle": "2022-02-15T16:14:11.080737Z",
     "shell.execute_reply": "2022-02-15T16:14:11.080147Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV 0 | Epoch 0 | Loss 3.0845658779144287\n",
      "CV 0 | Epoch 10 | Loss 3.0664035797119142\n",
      "CV 0 | Epoch 20 | Loss 3.030614447593689\n",
      "CV 0 | Epoch 30 | Loss 2.9882357358932494\n",
      "CV 0 | Epoch 40 | Loss 2.936527633666992\n",
      "CV 0 | Epoch 50 | Loss 2.875171446800232\n",
      "CV 0 | Epoch 60 | Loss 2.801808738708496\n",
      "CV 0 | Epoch 70 | Loss 2.7219006299972532\n",
      "CV 0 | Epoch 80 | Loss 2.6416470527648928\n",
      "CV 0 | Epoch 90 | Loss 2.564227318763733\n",
      "CV 0 | Epoch 100 | Loss 2.492985153198242\n",
      "CV 0 | Epoch 110 | Loss 2.4315430402755736\n",
      "CV 0 | Epoch 120 | Loss 2.382251477241516\n",
      "CV 0 | Epoch 130 | Loss 2.3459696531295777\n",
      "CV 0 | Epoch 140 | Loss 2.3210971117019654\n",
      "CV 0 | Epoch 150 | Loss 2.3044668197631837\n",
      "CV 0 | Epoch 160 | Loss 2.292884683609009\n",
      "CV 0 | Epoch 170 | Loss 2.2840600967407227\n",
      "CV 0 | Epoch 180 | Loss 2.276747465133667\n",
      "CV 0 | Epoch 190 | Loss 2.270322394371033\n",
      "CV 0 | Epoch 200 | Loss 2.2644838809967043\n",
      "CV 0 | Epoch 210 | Loss 2.259049129486084\n",
      "CV 0 | Epoch 220 | Loss 2.2539029359817504\n",
      "CV 0 | Epoch 230 | Loss 2.2489787101745606\n",
      "CV 0 | Epoch 240 | Loss 2.244237208366394\n",
      "CV 0 | Epoch 250 | Loss 2.239678406715393\n",
      "CV 0 | Epoch 260 | Loss 2.235252094268799\n",
      "CV 0 | Epoch 270 | Loss 2.230929374694824\n",
      "CV 0 | Epoch 280 | Loss 2.226699185371399\n",
      "CV 0 | Epoch 290 | Loss 2.222526216506958\n",
      "CV 0 | Epoch 300 | Loss 2.218399715423584\n",
      "CV 0 | Epoch 310 | Loss 2.2143102645874024\n",
      "CV 0 | Epoch 320 | Loss 2.2102527141571047\n",
      "CV 0 | Epoch 330 | Loss 2.206221508979797\n",
      "CV 0 | Epoch 340 | Loss 2.2022225856781006\n",
      "CV 0 | Epoch 350 | Loss 2.198226571083069\n",
      "CV 0 | Epoch 360 | Loss 2.1942338228225706\n",
      "CV 0 | Epoch 370 | Loss 2.190264129638672\n",
      "CV 0 | Epoch 380 | Loss 2.18629150390625\n",
      "CV 0 | Epoch 390 | Loss 2.1823580503463744\n",
      "CV 0 | Epoch 400 | Loss 2.1784457206726073\n",
      "CV 0 | Epoch 410 | Loss 2.174526739120483\n",
      "CV 0 | Epoch 420 | Loss 2.1705822229385374\n",
      "CV 0 | Epoch 430 | Loss 2.166642928123474\n",
      "CV 0 | Epoch 440 | Loss 2.162755250930786\n",
      "CV 0 | Epoch 450 | Loss 2.1588979959487915\n",
      "CV 0 | Epoch 460 | Loss 2.155067706108093\n",
      "CV 0 | Epoch 470 | Loss 2.151310658454895\n",
      "CV 0 | Epoch 480 | Loss 2.147603678703308\n",
      "CV 0 | Epoch 490 | Loss 2.1439422369003296\n",
      "CV 0 | Epoch 500 | Loss 2.140331530570984\n",
      "CV 0 | Epoch 510 | Loss 2.136758279800415\n",
      "CV 0 | Epoch 520 | Loss 2.13320255279541\n",
      "CV 0 | Epoch 530 | Loss 2.1296446084976197\n",
      "CV 0 | Epoch 540 | Loss 2.1260907888412475\n",
      "CV 0 | Epoch 550 | Loss 2.122587203979492\n",
      "CV 0 | Epoch 560 | Loss 2.1191511869430544\n",
      "CV 0 | Epoch 570 | Loss 2.1157562732696533\n",
      "CV 0 | Epoch 580 | Loss 2.112382698059082\n",
      "CV 0 | Epoch 590 | Loss 2.1090538024902346\n",
      "CV 0 | Epoch 600 | Loss 2.10577974319458\n",
      "CV 0 | Epoch 610 | Loss 2.1025600671768188\n",
      "CV 0 | Epoch 620 | Loss 2.0993855714797975\n",
      "CV 0 | Epoch 630 | Loss 2.0962663650512696\n",
      "CV 0 | Epoch 640 | Loss 2.093212890625\n",
      "CV 0 | Epoch 650 | Loss 2.090207839012146\n",
      "CV 0 | Epoch 660 | Loss 2.087240433692932\n",
      "CV 0 | Epoch 670 | Loss 2.0842824935913087\n",
      "CV 0 | Epoch 680 | Loss 2.081324887275696\n",
      "CV 0 | Epoch 690 | Loss 2.0783916234970095\n",
      "CV 0 | Epoch 700 | Loss 2.07548930644989\n",
      "CV 0 | Epoch 710 | Loss 2.0726204395294188\n",
      "CV 0 | Epoch 720 | Loss 2.069787335395813\n",
      "CV 0 | Epoch 730 | Loss 2.0670209169387816\n",
      "CV 0 | Epoch 740 | Loss 2.064356803894043\n",
      "CV 0 | Epoch 750 | Loss 2.061765265464783\n",
      "CV 0 | Epoch 760 | Loss 2.059220862388611\n",
      "CV 0 | Epoch 770 | Loss 2.0566803216934204\n",
      "CV 0 | Epoch 780 | Loss 2.054143524169922\n",
      "CV 0 | Epoch 790 | Loss 2.0516099452972414\n",
      "CV 0 | Epoch 800 | Loss 2.0491083383560182\n",
      "CV 0 | Epoch 810 | Loss 2.0466440677642823\n",
      "CV 0 | Epoch 820 | Loss 2.0441275119781492\n",
      "CV 0 | Epoch 830 | Loss 2.041583013534546\n",
      "CV 0 | Epoch 840 | Loss 2.0390772342681887\n",
      "CV 0 | Epoch 850 | Loss 2.0366106271743774\n",
      "CV 0 | Epoch 860 | Loss 2.034151315689087\n",
      "CV 0 | Epoch 870 | Loss 2.0316633939743043\n",
      "CV 0 | Epoch 880 | Loss 2.029174041748047\n",
      "CV 0 | Epoch 890 | Loss 2.026769256591797\n",
      "CV 0 | Epoch 900 | Loss 2.0244778871536253\n",
      "CV 0 | Epoch 910 | Loss 2.022231197357178\n",
      "CV 0 | Epoch 920 | Loss 2.020007681846619\n",
      "CV 0 | Epoch 930 | Loss 2.0176940679550173\n",
      "CV 0 | Epoch 940 | Loss 2.015154981613159\n",
      "CV 0 | Epoch 950 | Loss 2.012555384635925\n",
      "CV 0 | Epoch 960 | Loss 2.009939694404602\n",
      "CV 0 | Epoch 970 | Loss 2.0073630571365357\n",
      "CV 0 | Epoch 980 | Loss 2.0047992706298827\n",
      "CV 0 | Epoch 990 | Loss 2.0022077798843383\n",
      "CV 1 | Epoch 0 | Loss 3.2066428661346436\n",
      "CV 1 | Epoch 10 | Loss 3.185812211036682\n",
      "CV 1 | Epoch 20 | Loss 3.150491786003113\n",
      "CV 1 | Epoch 30 | Loss 3.118288040161133\n",
      "CV 1 | Epoch 40 | Loss 3.0881734132766723\n",
      "CV 1 | Epoch 50 | Loss 3.0588486433029174\n",
      "CV 1 | Epoch 60 | Loss 3.0294623613357543\n",
      "CV 1 | Epoch 70 | Loss 2.9991101264953612\n",
      "CV 1 | Epoch 80 | Loss 2.9669955253601072\n",
      "CV 1 | Epoch 90 | Loss 2.932116985321045\n",
      "CV 1 | Epoch 100 | Loss 2.8925945281982424\n",
      "CV 1 | Epoch 110 | Loss 2.8483540058135985\n",
      "CV 1 | Epoch 120 | Loss 2.8015841960906984\n",
      "CV 1 | Epoch 130 | Loss 2.756554675102234\n",
      "CV 1 | Epoch 140 | Loss 2.715381717681885\n",
      "CV 1 | Epoch 150 | Loss 2.6799338817596436\n",
      "CV 1 | Epoch 160 | Loss 2.651392865180969\n",
      "CV 1 | Epoch 170 | Loss 2.6296854257583617\n",
      "CV 1 | Epoch 180 | Loss 2.6137324571609497\n",
      "CV 1 | Epoch 190 | Loss 2.601977491378784\n",
      "CV 1 | Epoch 200 | Loss 2.592915105819702\n",
      "CV 1 | Epoch 210 | Loss 2.585422134399414\n",
      "CV 1 | Epoch 220 | Loss 2.578723907470703\n",
      "CV 1 | Epoch 230 | Loss 2.571952247619629\n",
      "CV 1 | Epoch 240 | Loss 2.5650002002716064\n",
      "CV 1 | Epoch 250 | Loss 2.5578777551651\n",
      "CV 1 | Epoch 260 | Loss 2.550546479225159\n",
      "CV 1 | Epoch 270 | Loss 2.543028450012207\n",
      "CV 1 | Epoch 280 | Loss 2.535373163223267\n",
      "CV 1 | Epoch 290 | Loss 2.5276299476623536\n",
      "CV 1 | Epoch 300 | Loss 2.5197834014892577\n",
      "CV 1 | Epoch 310 | Loss 2.511886978149414\n",
      "CV 1 | Epoch 320 | Loss 2.504009985923767\n",
      "CV 1 | Epoch 330 | Loss 2.496191143989563\n",
      "CV 1 | Epoch 340 | Loss 2.4884382009506227\n",
      "CV 1 | Epoch 350 | Loss 2.480765199661255\n",
      "CV 1 | Epoch 360 | Loss 2.473178339004517\n",
      "CV 1 | Epoch 370 | Loss 2.46568341255188\n",
      "CV 1 | Epoch 380 | Loss 2.4582889318466186\n",
      "CV 1 | Epoch 390 | Loss 2.450999140739441\n",
      "CV 1 | Epoch 400 | Loss 2.4438254594802857\n",
      "CV 1 | Epoch 410 | Loss 2.4367724657058716\n",
      "CV 1 | Epoch 420 | Loss 2.4298332929611206\n",
      "CV 1 | Epoch 430 | Loss 2.4230180263519285\n",
      "CV 1 | Epoch 440 | Loss 2.4163203477859496\n",
      "CV 1 | Epoch 450 | Loss 2.409727764129639\n",
      "CV 1 | Epoch 460 | Loss 2.403212285041809\n",
      "CV 1 | Epoch 470 | Loss 2.3967276573181153\n",
      "CV 1 | Epoch 480 | Loss 2.390308451652527\n",
      "CV 1 | Epoch 490 | Loss 2.384057807922363\n",
      "CV 1 | Epoch 500 | Loss 2.377957844734192\n",
      "CV 1 | Epoch 510 | Loss 2.3719783544540407\n",
      "CV 1 | Epoch 520 | Loss 2.366094207763672\n",
      "CV 1 | Epoch 530 | Loss 2.3603024244308473\n",
      "CV 1 | Epoch 540 | Loss 2.3546003103256226\n",
      "CV 1 | Epoch 550 | Loss 2.34898464679718\n",
      "CV 1 | Epoch 560 | Loss 2.3434677362442016\n",
      "CV 1 | Epoch 570 | Loss 2.3380431175231933\n",
      "CV 1 | Epoch 580 | Loss 2.3326959371566773\n",
      "CV 1 | Epoch 590 | Loss 2.327423882484436\n",
      "CV 1 | Epoch 600 | Loss 2.322245240211487\n",
      "CV 1 | Epoch 610 | Loss 2.3171687602996824\n",
      "CV 1 | Epoch 620 | Loss 2.3121764421463014\n",
      "CV 1 | Epoch 630 | Loss 2.307255816459656\n",
      "CV 1 | Epoch 640 | Loss 2.302396464347839\n",
      "CV 1 | Epoch 650 | Loss 2.297597146034241\n",
      "CV 1 | Epoch 660 | Loss 2.292856812477112\n",
      "CV 1 | Epoch 670 | Loss 2.288173031806946\n",
      "CV 1 | Epoch 680 | Loss 2.283547616004944\n",
      "CV 1 | Epoch 690 | Loss 2.2789803981781005\n",
      "CV 1 | Epoch 700 | Loss 2.2744665861129763\n",
      "CV 1 | Epoch 710 | Loss 2.2700130701065064\n",
      "CV 1 | Epoch 720 | Loss 2.2656232118606567\n",
      "CV 1 | Epoch 730 | Loss 2.2612472772598267\n",
      "CV 1 | Epoch 740 | Loss 2.2569035291671753\n",
      "CV 1 | Epoch 750 | Loss 2.2526031732559204\n",
      "CV 1 | Epoch 760 | Loss 2.2483613967895506\n",
      "CV 1 | Epoch 770 | Loss 2.2441752672195436\n",
      "CV 1 | Epoch 780 | Loss 2.240050220489502\n",
      "CV 1 | Epoch 790 | Loss 2.235974836349487\n",
      "CV 1 | Epoch 800 | Loss 2.231944465637207\n",
      "CV 1 | Epoch 810 | Loss 2.227958345413208\n",
      "CV 1 | Epoch 820 | Loss 2.224008393287659\n",
      "CV 1 | Epoch 830 | Loss 2.220094108581543\n",
      "CV 1 | Epoch 840 | Loss 2.216222810745239\n",
      "CV 1 | Epoch 850 | Loss 2.2123944759368896\n",
      "CV 1 | Epoch 860 | Loss 2.2086132764816284\n",
      "CV 1 | Epoch 870 | Loss 2.2048663854599\n",
      "CV 1 | Epoch 880 | Loss 2.2011646032333374\n",
      "CV 1 | Epoch 890 | Loss 2.1975127696990966\n",
      "CV 1 | Epoch 900 | Loss 2.1938894033432006\n",
      "CV 1 | Epoch 910 | Loss 2.190300130844116\n",
      "CV 1 | Epoch 920 | Loss 2.1867414474487306\n",
      "CV 1 | Epoch 930 | Loss 2.183215093612671\n",
      "CV 1 | Epoch 940 | Loss 2.1797213554382324\n",
      "CV 1 | Epoch 950 | Loss 2.176265001296997\n",
      "CV 1 | Epoch 960 | Loss 2.172842192649841\n",
      "CV 1 | Epoch 970 | Loss 2.169451689720154\n",
      "CV 1 | Epoch 980 | Loss 2.1660942792892457\n",
      "CV 1 | Epoch 990 | Loss 2.1627727270126345\n"
     ]
    }
   ],
   "source": [
    "th_device = th.device(device)\n",
    "\n",
    "metrics = []\n",
    "confusion_matrix = []\n",
    "syn_pred = []\n",
    "ev = Evaluator()\n",
    "\n",
    "th_device = th.device(device)\n",
    "\n",
    "syn_index = ['prev_punishments', 'prev_contributions']\n",
    "\n",
    "def create_fully_connected(n_nodes):\n",
    "    return th.tensor([[i,j]\n",
    "        for i in range(n_nodes)\n",
    "        for j in range(n_nodes)\n",
    "    ]).T\n",
    "\n",
    "def encode(model, data, *, mask=True, index=False, x_encode=True, y_encode=True, u_encode=False, device, n_player=4):\n",
    "    data = {\n",
    "        'mask': data['valid'] if mask else None,\n",
    "        'x': model.x_encoder(**data) if x_encode else None,\n",
    "        'y_enc': model.y_encoder(**data) if y_encode else None,\n",
    "        'y': data['contributions'] if y_encode else None,\n",
    "        'u': model.u_encoder(**data) if u_encode and hasattr(model, 'u_encoder') else None,\n",
    "        'info': th.stack([data[c] for c in syn_index], dim=-1) if index else None,\n",
    "    }\n",
    "    data = {\n",
    "        k: v.to(device)\n",
    "        for k, v in data.items()\n",
    "        if v is not None\n",
    "    }\n",
    "\n",
    "    n_episodes, n_agents, n_rounds, _ = data['x'].shape\n",
    "\n",
    "    edge_attr = th.zeros(n_player*n_player, n_rounds,0)\n",
    "    edge_index = create_fully_connected(n_player)\n",
    "\n",
    "    n_episodes = list(data.values())[0].shape[0]\n",
    "    dataset = [\n",
    "        Data(**{k: v[i] for k, v in data.items()}, edge_attr=edge_attr, edge_index=edge_index, idx=i, group_idx=i, num_nodes=n_player)\n",
    "        for i in range(n_episodes)\n",
    "    ]\n",
    "    return dataset\n",
    "\n",
    "def shuffle_feature(data, feature_name):\n",
    "    data = {**data}\n",
    "    data[feature_name] = data[feature_name][th.randperm(len(data[feature_name]))]\n",
    "    return data\n",
    "\n",
    "for i, (train_data, test_data) in enumerate(get_cross_validations(data, n_cross_val, fraction_training)):\n",
    "    model = AH_MODELS[model_name](\n",
    "        n_contributions=n_contributions, n_punishments=n_punishments,\n",
    "        **model_args).to(th_device)\n",
    "\n",
    "    train_data_ = encode(model, train_data, mask=True, u_encode=True, device=th_device)\n",
    "    test_data_ = encode(model, test_data, mask=True, u_encode=True, device=th_device)\n",
    "    syn_data_ = encode(model, syn_data, mask=False, y_encode=False, u_encode=True, index=True, device=th_device)\n",
    "\n",
    "    syn_df = using_multiindex(\n",
    "        Batch.from_data_list(syn_data_)['info'], ['idx', 'round_number'], syn_index)\n",
    "\n",
    "    optimizer = th.optim.Adam(model.parameters(), **optimizer_args)\n",
    "    loss_fn = th.nn.CrossEntropyLoss(reduction='none')\n",
    "    sum_loss = 0\n",
    "    n_steps = 0\n",
    "\n",
    "    for e in range(train_args['epochs']):\n",
    "        ev.set_labels(cv_split=i, epoch=e)\n",
    "        model.train()\n",
    "        for j, batch_data in enumerate(iter(DataLoader(train_data_, shuffle=True, batch_size=train_args['batch_size']))):\n",
    "            optimizer.zero_grad()\n",
    "            py = model(batch_data).flatten(end_dim=-2)\n",
    "            y_true = batch_data['y_enc'].flatten(end_dim=-2)\n",
    "            mask = batch_data['mask'].flatten()\n",
    "            loss = loss_fn(py, y_true)\n",
    "            loss = (loss * mask).sum() / mask.sum()\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            if train_args['clamp_grad']:\n",
    "                for param in model.parameters():\n",
    "                    param.grad.data.clamp_(-train_args['clamp_grad'], train_args['clamp_grad'])\n",
    "            optimizer.step()\n",
    "            sum_loss += loss.item()\n",
    "            n_steps +=1\n",
    "        \n",
    "        if e % train_args['eval_period'] == 0:\n",
    "            avg_loss = sum_loss/n_steps\n",
    "            print(f'CV {i} | Epoch {e} | Loss {avg_loss}')\n",
    "            ev.add_loss(avg_loss)\n",
    "\n",
    "            ev.eval_set(model, train_data_, set='train')\n",
    "            ev.eval_set(model, test_data_, set='test')\n",
    "            for sf in shuffle_features:\n",
    "                shuffled_data = shuffle_feature(test_data, sf)\n",
    "                shuffled_data = encode(model, shuffled_data, mask=True, u_encode=True, device=th_device)\n",
    "                ev.eval_set(model, shuffled_data, set='test', shuffle_feature=sf)\n",
    "            sum_loss = 0\n",
    "            n_steps = 0\n",
    "    ev.eval_syn(model, syn_data_, syn_df)\n",
    "\n",
    "ev.save(output_path, labels)\n",
    "model_path = os.path.join(output_path, 'model.pt')\n",
    "model.save(model_path)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b1198fd9370ee0cf82025240fa26724f68bfab1e3f74dbb4acdc06e7861d0dbe"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5.747884,
   "end_time": "2022-04-19T16:41:32.101998",
   "environment_variables": {},
   "exception": true,
   "input_path": "notebooks/artificial_humans/graph.ipynb",
   "output_path": "notebooks/artificial_humans/graph.ipynb",
   "parameters": {
    "data_file": "../../data/experiments/pilot_random1_player_round_slim.csv",
    "device": "cpu",
    "fraction_training": 1,
    "labels": {},
    "model_args": {
     "add_edge_model": false,
     "add_global_model": false,
     "add_rnn": false,
     "hidden_size": 10,
     "u_encoding": [
      {
       "etype": "float",
       "name": "prev_common_good",
       "norm": 128
      }
     ],
     "x_encoding": [
      {
       "encoding": "numeric",
       "n_levels": 21,
       "name": "prev_contributions"
      },
      {
       "encoding": "numeric",
       "n_levels": 31,
       "name": "prev_punishments"
      },
      {
       "encoding": "numeric",
       "n_levels": 16,
       "name": "round_number"
      },
      {
       "etype": "float",
       "name": "prev_common_good",
       "norm": 128
      },
      {
       "etype": "bool",
       "name": "prev_valid"
      }
     ]
    },
    "model_name": "graph",
    "n_contributions": 21,
    "n_cross_val": 2,
    "n_punishments": 31,
    "optimizer_args": {
     "lr": 0.0001,
     "weight_decay": 0.00001
    },
    "output_path": "../../data/training/dev",
    "train_args": {
     "batch_size": 20,
     "clamp_grad": 1,
     "epochs": 100,
     "eval_period": 10
    }
   },
   "start_time": "2022-04-19T16:41:26.354114",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
