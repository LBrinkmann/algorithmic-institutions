{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39174ec3",
   "metadata": {
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "n_contributions = 21\n",
    "n_punishments = 31\n",
    "n_cross_val = 2\n",
    "fraction_training = 1.0\n",
    "data_file = \"../../data/experiments/pilot_random1_player_round_slim.csv\"\n",
    "output_path = \"../../data/training/dev\"\n",
    "labels = {}\n",
    "model_name = \"graph\"\n",
    "model_args = {\n",
    "    \"add_rnn\": False,\n",
    "    \"add_edge_model\": False,\n",
    "    \"add_global_model\": False,\n",
    "    \"hidden_size\": 10,\n",
    "    \"x_encoding\": [\n",
    "        {\"name\": \"prev_contributions\", \"n_levels\": 21, \"encoding\": \"numeric\"},\n",
    "        {\"name\": \"prev_punishments\", \"n_levels\": 31, \"encoding\": \"numeric\"},\n",
    "        {\"name\": \"round_number\", \"n_levels\": 16, \"encoding\": \"numeric\"},\n",
    "        {\"name\": \"prev_common_good\", \"norm\": 128, \"etype\": \"float\"},\n",
    "        {\"name\": \"prev_valid\", \"etype\": \"bool\"},\n",
    "    ],\n",
    "    \"u_encoding\": [{\"name\": \"prev_common_good\", \"norm\": 128, \"etype\": \"float\"}],\n",
    "}\n",
    "optimizer_args = {\"lr\": 0.0001, \"weight_decay\": 1e-05}\n",
    "train_args = {\"epochs\": 100, \"batch_size\": 20, \"clamp_grad\": 1, \"eval_period\": 10}\n",
    "device = \"cpu\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44582683",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-19T16:41:27.956497Z",
     "iopub.status.busy": "2022-04-19T16:41:27.956108Z",
     "iopub.status.idle": "2022-04-19T16:41:30.638413Z",
     "shell.execute_reply": "2022-04-19T16:41:30.637779Z"
    },
    "papermill": {
     "duration": 2.691081,
     "end_time": "2022-04-19T16:41:30.640419",
     "exception": false,
     "start_time": "2022-04-19T16:41:27.949338",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch as th\n",
    "from aimanager.generic.data import create_syn_data, create_torch_data, get_cross_validations\n",
    "from aimanager.artificial_humans import AH_MODELS\n",
    "from aimanager.artificial_humans.evaluation import Evaluator\n",
    "from aimanager.utils.array_to_df import using_multiindex\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "output_path = os.path.join(output_path, 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e6659c46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-15T16:13:44.221298Z",
     "iopub.status.busy": "2022-02-15T16:13:44.220802Z",
     "iopub.status.idle": "2022-02-15T16:13:44.264216Z",
     "shell.execute_reply": "2022-02-15T16:13:44.263653Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_file)\n",
    "\n",
    "\n",
    "data = create_torch_data(df)\n",
    "syn_data = create_syn_data(n_contribution=21, n_punishment=31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "660e103c",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.nn import Sequential as Seq, Linear as Lin, Tanh, GRU\n",
    "import torch as th\n",
    "from torch_scatter import scatter_mean\n",
    "from torch_geometric.nn import MetaLayer\n",
    "from aimanager.generic.encoder import Encoder, IntEncoder\n",
    "\n",
    "\n",
    "class EdgeModel(th.nn.Module):\n",
    "    def __init__(self, x_features, edge_features, u_features, out_features):\n",
    "        super().__init__()\n",
    "        in_features = 2*x_features+edge_features+u_features\n",
    "        self.edge_mlp = Seq(Lin(in_features=in_features, out_features=out_features), Tanh())\n",
    "\n",
    "    def forward(self, src, dest, edge_attr, u, batch):\n",
    "        # src, dest: [E, F_x], where E is the number of edges.\n",
    "        # edge_attr: [E, F_e]\n",
    "        # u: [B, F_u], where B is the number of graphs.\n",
    "        # batch: [E] with max entry B - 1.\n",
    "        out = th.cat([src, dest, edge_attr, u[batch]], dim=-1)\n",
    "        out = self.edge_mlp(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class NodeModel(th.nn.Module):\n",
    "    def __init__(self, x_features, edge_features, u_features, out_features):\n",
    "        super().__init__()\n",
    "        in_features = x_features+edge_features+u_features\n",
    "        self.node_mlp = Seq(Lin(in_features=in_features, out_features=out_features), Tanh())\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, u, batch):\n",
    "        # x: [N, F_x], where N is the number of nodes.\n",
    "        # edge_index: [2, E] with max entry N - 1.\n",
    "        # edge_attr: [E, F_e]\n",
    "        # u: [B, F_u]\n",
    "        # batch: [N] with max entry B - 1.\n",
    "\n",
    "        row, col = edge_index\n",
    "        out = scatter_mean(edge_attr, col, dim=0, dim_size=x.size(0))\n",
    "        out = th.cat([x, out, u[batch]], dim=-1)\n",
    "        out = self.node_mlp(out)\n",
    "        return out\n",
    "\n",
    "class GlobalModel(th.nn.Module):\n",
    "    def __init__(self, x_features, edge_features, u_features, out_features):\n",
    "        super().__init__()\n",
    "        in_features = u_features+x_features\n",
    "        self.global_mlp = Seq(Lin(in_features=in_features, out_features=out_features), Tanh())\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, u, batch):\n",
    "        # x: [N, F_x], where N is the number of nodes.\n",
    "        # edge_index: [2, E] with max entry N - 1.\n",
    "        # edge_attr: [E, F_e]\n",
    "        # u: [B, F_u]\n",
    "        # batch: [N] with max entry B - 1.\n",
    "        out = th.cat([u, scatter_mean(x, batch, dim=0)], dim=-1)\n",
    "        return self.global_mlp(out)\n",
    "\n",
    "class GraphNetwork(th.nn.Module):\n",
    "    def __init__(self, n_contributions, n_punishments, x_encoding, u_encoding, add_rnn=True, add_edge_model=True, \n",
    "            add_global_model=True, hidden_size=None, op1=None, op2=None, rnn_n=None, rnn_g=None):\n",
    "        super().__init__()\n",
    "        self.x_encoder = Encoder(x_encoding)\n",
    "        self.u_encoder = Encoder(u_encoding, aggregation='mean')\n",
    "        self.y_encoder = IntEncoder(encoding='onehot', name='contributions', n_levels=n_contributions)\n",
    "        x_features = self.x_encoder.size\n",
    "        u_features = self.u_encoder.size\n",
    "        y_features = self.y_encoder.size\n",
    "        self.n_contributions = n_contributions\n",
    "        self.n_punishments = n_punishments\n",
    "        self.x_encoding = x_encoding\n",
    "        self.u_encoding = u_encoding\n",
    "\n",
    "        edge_features = 0\n",
    "        if op1 is None:\n",
    "            if add_edge_model:\n",
    "                edge_model = EdgeModel(\n",
    "                    x_features=x_features, edge_features=edge_features, \n",
    "                    u_features=u_features, out_features=hidden_size)\n",
    "                edge_features = hidden_size\n",
    "            else:\n",
    "                edge_model = None\n",
    "\n",
    "            node_model = NodeModel(\n",
    "                x_features=x_features, edge_features=edge_features, \n",
    "                u_features=u_features, out_features=hidden_size)\n",
    "            x_features = hidden_size\n",
    "\n",
    "            if add_global_model:\n",
    "                gobal_model = GlobalModel(\n",
    "                    x_features=x_features, edge_features=edge_features, \n",
    "                    u_features=u_features, out_features=hidden_size)\n",
    "                u_features = hidden_size\n",
    "            else:\n",
    "                gobal_model = None\n",
    "\n",
    "            self.op1 = MetaLayer(edge_model, node_model, gobal_model)\n",
    "\n",
    "            if add_rnn:\n",
    "                self.rnn_n = GRU(input_size=x_features, hidden_size=hidden_size, num_layers=1, batch_first=True)\n",
    "                x_features = hidden_size\n",
    "            else:\n",
    "                self.rnn_n = None\n",
    "\n",
    "            if add_rnn and add_global_model:\n",
    "                self.rnn_g = GRU(input_size=u_features, hidden_size=hidden_size, num_layers=1, batch_first=True)\n",
    "                u_features = hidden_size\n",
    "            else:\n",
    "                self.rnn_g = None\n",
    "\n",
    "\n",
    "            self.op2 = MetaLayer(\n",
    "                None,\n",
    "                NodeModel(\n",
    "                    x_features=x_features, edge_features=0, \n",
    "                    u_features=u_features, out_features=y_features), \n",
    "                None\n",
    "            )\n",
    "        else:\n",
    "            self.op1 = op1\n",
    "            self.op2 = op2\n",
    "            self.rnn_n = rnn_n\n",
    "            self.rnn_g = rnn_g\n",
    "    \n",
    "    def forward(self, data):\n",
    "        x = data['x']\n",
    "        edge_index = data['edge_index']\n",
    "        edge_attr = data['edge_attr']\n",
    "        u = data['u']\n",
    "        batch = data['batch']\n",
    "        x, _, u = self.op1(x, edge_index, edge_attr, u, batch)\n",
    "        if self.rnn_n is not None:\n",
    "            x, x_h_n = self.rnn_n(x)\n",
    "        if self.rnn_g is not None:\n",
    "            u, u_h_n = self.rnn_g(u)\n",
    "        x, _, _ = self.op2(x, edge_index, edge_attr, u, batch)\n",
    "        return x\n",
    "\n",
    "    def predict(self, data):\n",
    "        self.eval()\n",
    "        y_pred_logit = th.cat([self(d)\n",
    "            for d in iter(DataLoader(data, shuffle=False, batch_size=10))\n",
    "        ])\n",
    "        y_pred_proba = th.nn.functional.softmax(y_pred_logit, dim=-1)\n",
    "        y_pred = self.y_encoder.decode(y_pred_proba)\n",
    "        return y_pred, y_pred_proba\n",
    "\n",
    "    def save(self, filename):\n",
    "        to_save = {\n",
    "            'op1': self.op1,\n",
    "            'op2': self.op2,\n",
    "            'n_contributions': self.n_contributions,\n",
    "            'n_punishments': self.n_punishments,\n",
    "            'x_encoding': self.x_encoding, \n",
    "            'u_encoding': self.u_encoding\n",
    "        }\n",
    "        th.save(to_save, filename)\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, filename):\n",
    "        to_load = th.load(filename)\n",
    "        ah = cls(**to_load)\n",
    "        return ah\n",
    "\n",
    "\n",
    "AH_MODELS['graph'] = GraphNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1f144b88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-15T16:13:44.354450Z",
     "iopub.status.busy": "2022-02-15T16:13:44.354021Z",
     "iopub.status.idle": "2022-02-15T16:14:11.080737Z",
     "shell.execute_reply": "2022-02-15T16:14:11.080147Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135 4 16\n",
      "68 4 16\n",
      "651 4 16\n",
      "135\n",
      "CV 0 | Epoch 0 | Loss 3.002033531665802\n",
      "CV 0 | Epoch 10 | Loss 2.9787950098514555\n",
      "CV 0 | Epoch 20 | Loss 2.934113270044327\n",
      "CV 0 | Epoch 30 | Loss 2.8964249014854433\n",
      "CV 0 | Epoch 40 | Loss 2.8641567826271057\n",
      "CV 0 | Epoch 50 | Loss 2.8278100907802584\n",
      "CV 0 | Epoch 60 | Loss 2.7998156607151032\n",
      "CV 0 | Epoch 70 | Loss 2.769683337211609\n",
      "CV 0 | Epoch 80 | Loss 2.739825940132141\n",
      "CV 0 | Epoch 90 | Loss 2.7287934601306914\n",
      "CV 0 | Epoch 100 | Loss 2.7053283512592317\n",
      "CV 0 | Epoch 110 | Loss 2.687431734800339\n",
      "CV 0 | Epoch 120 | Loss 2.6718005537986755\n",
      "CV 0 | Epoch 130 | Loss 2.668984192609787\n",
      "CV 0 | Epoch 140 | Loss 2.658408296108246\n",
      "CV 0 | Epoch 150 | Loss 2.644911986589432\n",
      "CV 0 | Epoch 160 | Loss 2.627376216650009\n",
      "CV 0 | Epoch 170 | Loss 2.6234934329986572\n",
      "CV 0 | Epoch 180 | Loss 2.6200892984867097\n",
      "CV 0 | Epoch 190 | Loss 2.6037919342517855\n",
      "CV 0 | Epoch 200 | Loss 2.608202576637268\n",
      "CV 0 | Epoch 210 | Loss 2.5978466272354126\n",
      "CV 0 | Epoch 220 | Loss 2.6030715227127077\n",
      "CV 0 | Epoch 230 | Loss 2.591943824291229\n",
      "CV 0 | Epoch 240 | Loss 2.594506961107254\n",
      "CV 0 | Epoch 250 | Loss 2.5831467747688293\n",
      "CV 0 | Epoch 260 | Loss 2.5785385966300964\n",
      "CV 0 | Epoch 270 | Loss 2.577757453918457\n",
      "CV 0 | Epoch 280 | Loss 2.5744409620761872\n",
      "CV 0 | Epoch 290 | Loss 2.5586486160755157\n",
      "CV 0 | Epoch 300 | Loss 2.5685652613639833\n",
      "CV 0 | Epoch 310 | Loss 2.5642746448516847\n",
      "CV 0 | Epoch 320 | Loss 2.5660680413246153\n",
      "CV 0 | Epoch 330 | Loss 2.5706446409225463\n",
      "CV 0 | Epoch 340 | Loss 2.5518848419189455\n",
      "CV 0 | Epoch 350 | Loss 2.556830531358719\n",
      "CV 0 | Epoch 360 | Loss 2.5626194417476653\n",
      "CV 0 | Epoch 370 | Loss 2.562441122531891\n",
      "CV 0 | Epoch 380 | Loss 2.5516413331031798\n",
      "CV 0 | Epoch 390 | Loss 2.5466980159282686\n",
      "CV 0 | Epoch 400 | Loss 2.5411216139793398\n",
      "CV 0 | Epoch 410 | Loss 2.564194506406784\n",
      "CV 0 | Epoch 420 | Loss 2.5495187878608703\n",
      "CV 0 | Epoch 430 | Loss 2.5464750587940217\n",
      "CV 0 | Epoch 440 | Loss 2.541780287027359\n",
      "CV 0 | Epoch 450 | Loss 2.5327000975608827\n",
      "CV 0 | Epoch 460 | Loss 2.5480107724666596\n",
      "CV 0 | Epoch 470 | Loss 2.5494698166847227\n",
      "CV 0 | Epoch 480 | Loss 2.5426037907600403\n",
      "CV 0 | Epoch 490 | Loss 2.542291921377182\n",
      "CV 0 | Epoch 500 | Loss 2.530319023132324\n",
      "CV 0 | Epoch 510 | Loss 2.538042938709259\n",
      "CV 0 | Epoch 520 | Loss 2.5453484058380127\n",
      "CV 0 | Epoch 530 | Loss 2.5243934273719786\n",
      "CV 0 | Epoch 540 | Loss 2.529150480031967\n",
      "CV 0 | Epoch 550 | Loss 2.535460263490677\n",
      "CV 0 | Epoch 560 | Loss 2.5391020238399507\n",
      "CV 0 | Epoch 570 | Loss 2.5377297699451447\n",
      "CV 0 | Epoch 580 | Loss 2.529537171125412\n",
      "CV 0 | Epoch 590 | Loss 2.526219516992569\n",
      "CV 0 | Epoch 600 | Loss 2.5165142178535462\n",
      "CV 0 | Epoch 610 | Loss 2.5256690084934235\n",
      "CV 0 | Epoch 620 | Loss 2.5271803975105285\n",
      "CV 0 | Epoch 630 | Loss 2.529519820213318\n",
      "CV 0 | Epoch 640 | Loss 2.51887925863266\n",
      "CV 0 | Epoch 650 | Loss 2.5244450211524962\n",
      "CV 0 | Epoch 660 | Loss 2.5211918890476226\n",
      "CV 0 | Epoch 670 | Loss 2.514464497566223\n",
      "CV 0 | Epoch 680 | Loss 2.515584206581116\n",
      "CV 0 | Epoch 690 | Loss 2.511191928386688\n",
      "CV 0 | Epoch 700 | Loss 2.511714202165604\n",
      "CV 0 | Epoch 710 | Loss 2.510315865278244\n",
      "CV 0 | Epoch 720 | Loss 2.497482717037201\n",
      "CV 0 | Epoch 730 | Loss 2.5217610776424406\n",
      "CV 0 | Epoch 740 | Loss 2.511834752559662\n",
      "CV 0 | Epoch 750 | Loss 2.502953606843948\n",
      "CV 0 | Epoch 760 | Loss 2.5126819610595703\n",
      "CV 0 | Epoch 770 | Loss 2.5000765919685364\n",
      "CV 0 | Epoch 780 | Loss 2.50984006524086\n",
      "CV 0 | Epoch 790 | Loss 2.506247711181641\n",
      "CV 0 | Epoch 800 | Loss 2.5103345036506655\n",
      "CV 0 | Epoch 810 | Loss 2.494755482673645\n",
      "CV 0 | Epoch 820 | Loss 2.5049702703952788\n",
      "CV 0 | Epoch 830 | Loss 2.5001793026924135\n",
      "CV 0 | Epoch 840 | Loss 2.5054669082164764\n",
      "CV 0 | Epoch 850 | Loss 2.497219610214233\n",
      "CV 0 | Epoch 860 | Loss 2.4958147764205934\n",
      "CV 0 | Epoch 870 | Loss 2.5013492882251738\n",
      "CV 0 | Epoch 880 | Loss 2.503452092409134\n",
      "CV 0 | Epoch 890 | Loss 2.495056664943695\n",
      "CV 0 | Epoch 900 | Loss 2.496879905462265\n",
      "CV 0 | Epoch 910 | Loss 2.492558091878891\n",
      "CV 0 | Epoch 920 | Loss 2.5063074469566344\n",
      "CV 0 | Epoch 930 | Loss 2.505317384004593\n",
      "CV 0 | Epoch 940 | Loss 2.501815211772919\n",
      "CV 0 | Epoch 950 | Loss 2.484736317396164\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/levinbrinkmann/repros/algorithmic-institutions/notebooks/artificial_humans/graph.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 47>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/levinbrinkmann/repros/algorithmic-institutions/notebooks/artificial_humans/graph.ipynb#ch0000004?line=90'>91</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mCV \u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m | Epoch \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m | Loss \u001b[39m\u001b[39m{\u001b[39;00mavg_loss\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/levinbrinkmann/repros/algorithmic-institutions/notebooks/artificial_humans/graph.ipynb#ch0000004?line=91'>92</a>\u001b[0m ev\u001b[39m.\u001b[39madd_loss(avg_loss)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/levinbrinkmann/repros/algorithmic-institutions/notebooks/artificial_humans/graph.ipynb#ch0000004?line=92'>93</a>\u001b[0m ev\u001b[39m.\u001b[39;49meval_set(model, \u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/levinbrinkmann/repros/algorithmic-institutions/notebooks/artificial_humans/graph.ipynb#ch0000004?line=93'>94</a>\u001b[0m ev\u001b[39m.\u001b[39meval_set(model, \u001b[39m'\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/levinbrinkmann/repros/algorithmic-institutions/notebooks/artificial_humans/graph.ipynb#ch0000004?line=94'>95</a>\u001b[0m sum_loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/repros/algorithmic-institutions/aimanager/artificial_humans/evaluation.py:50\u001b[0m, in \u001b[0;36mEvaluator.eval_set\u001b[0;34m(self, model, set_name)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/levinbrinkmann/repros/algorithmic-institutions/aimanager/artificial_humans/evaluation.py?line=46'>47</a>\u001b[0m y_true \u001b[39m=\u001b[39m y_true\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m     <a href='file:///Users/levinbrinkmann/repros/algorithmic-institutions/aimanager/artificial_humans/evaluation.py?line=47'>48</a>\u001b[0m y_pred \u001b[39m=\u001b[39m y_pred\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()\n\u001b[0;32m---> <a href='file:///Users/levinbrinkmann/repros/algorithmic-institutions/aimanager/artificial_humans/evaluation.py?line=49'>50</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetrics \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m create_metrics(y_true, y_pred, \u001b[39mset\u001b[39;49m\u001b[39m=\u001b[39;49mset_name, strategy\u001b[39m=\u001b[39;49mstrategy, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlabels)\n\u001b[1;32m     <a href='file:///Users/levinbrinkmann/repros/algorithmic-institutions/aimanager/artificial_humans/evaluation.py?line=50'>51</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfusion_matrix \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m create_confusion_matrix(\n\u001b[1;32m     <a href='file:///Users/levinbrinkmann/repros/algorithmic-institutions/aimanager/artificial_humans/evaluation.py?line=51'>52</a>\u001b[0m     y_true, y_pred, \u001b[39mset\u001b[39m\u001b[39m=\u001b[39mset_name, strategy\u001b[39m=\u001b[39mstrategy, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabels)\n",
      "File \u001b[0;32m~/repros/algorithmic-institutions/aimanager/artificial_humans/metrics.py:6\u001b[0m, in \u001b[0;36mcreate_metrics\u001b[0;34m(y_true, y_pred, **labels)\u001b[0m\n\u001b[1;32m      <a href='file:///Users/levinbrinkmann/repros/algorithmic-institutions/aimanager/artificial_humans/metrics.py?line=4'>5</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate_metrics\u001b[39m(y_true, y_pred, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mlabels):\n\u001b[0;32m----> <a href='file:///Users/levinbrinkmann/repros/algorithmic-institutions/aimanager/artificial_humans/metrics.py?line=5'>6</a>\u001b[0m     accuracy \u001b[39m=\u001b[39m accuracy_score(y_true, y_pred)\n\u001b[1;32m      <a href='file:///Users/levinbrinkmann/repros/algorithmic-institutions/aimanager/artificial_humans/metrics.py?line=6'>7</a>\u001b[0m     mabserr \u001b[39m=\u001b[39m mean_absolute_error(y_true, y_pred)\n\u001b[1;32m      <a href='file:///Users/levinbrinkmann/repros/algorithmic-institutions/aimanager/artificial_humans/metrics.py?line=7'>8</a>\u001b[0m     metrics \u001b[39m=\u001b[39m [\n\u001b[1;32m      <a href='file:///Users/levinbrinkmann/repros/algorithmic-institutions/aimanager/artificial_humans/metrics.py?line=8'>9</a>\u001b[0m     {\n\u001b[1;32m     <a href='file:///Users/levinbrinkmann/repros/algorithmic-institutions/aimanager/artificial_humans/metrics.py?line=9'>10</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mmean_absolute_error\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/levinbrinkmann/repros/algorithmic-institutions/aimanager/artificial_humans/metrics.py?line=17'>18</a>\u001b[0m     }\n\u001b[1;32m     <a href='file:///Users/levinbrinkmann/repros/algorithmic-institutions/aimanager/artificial_humans/metrics.py?line=18'>19</a>\u001b[0m     ]\n",
      "File \u001b[0;32m~/repros/algorithmic-institutions/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:211\u001b[0m, in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/levinbrinkmann/repros/algorithmic-institutions/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=144'>145</a>\u001b[0m \u001b[39m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/levinbrinkmann/repros/algorithmic-institutions/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=145'>146</a>\u001b[0m \n\u001b[1;32m    <a href='file:///Users/levinbrinkmann/repros/algorithmic-institutions/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=146'>147</a>\u001b[0m \u001b[39mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/levinbrinkmann/repros/algorithmic-institutions/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=206'>207</a>\u001b[0m \u001b[39m0.5\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/levinbrinkmann/repros/algorithmic-institutions/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=207'>208</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/levinbrinkmann/repros/algorithmic-institutions/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=209'>210</a>\u001b[0m \u001b[39m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[0;32m--> <a href='file:///Users/levinbrinkmann/repros/algorithmic-institutions/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=210'>211</a>\u001b[0m y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[1;32m    <a href='file:///Users/levinbrinkmann/repros/algorithmic-institutions/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=211'>212</a>\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    <a href='file:///Users/levinbrinkmann/repros/algorithmic-institutions/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=212'>213</a>\u001b[0m \u001b[39mif\u001b[39;00m y_type\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39mmultilabel\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m~/repros/algorithmic-institutions/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:86\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/levinbrinkmann/repros/algorithmic-institutions/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=83'>84</a>\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[1;32m     <a href='file:///Users/levinbrinkmann/repros/algorithmic-institutions/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=84'>85</a>\u001b[0m type_true \u001b[39m=\u001b[39m type_of_target(y_true, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my_true\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='file:///Users/levinbrinkmann/repros/algorithmic-institutions/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=85'>86</a>\u001b[0m type_pred \u001b[39m=\u001b[39m type_of_target(y_pred, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39my_pred\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     <a href='file:///Users/levinbrinkmann/repros/algorithmic-institutions/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=87'>88</a>\u001b[0m y_type \u001b[39m=\u001b[39m {type_true, type_pred}\n\u001b[1;32m     <a href='file:///Users/levinbrinkmann/repros/algorithmic-institutions/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=88'>89</a>\u001b[0m \u001b[39mif\u001b[39;00m y_type \u001b[39m==\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m}:\n",
      "File \u001b[0;32m~/repros/algorithmic-institutions/.venv/lib/python3.9/site-packages/sklearn/utils/multiclass.py:335\u001b[0m, in \u001b[0;36mtype_of_target\u001b[0;34m(y, input_name)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/levinbrinkmann/repros/algorithmic-institutions/.venv/lib/python3.9/site-packages/sklearn/utils/multiclass.py?line=331'>332</a>\u001b[0m     _assert_all_finite(y, input_name\u001b[39m=\u001b[39minput_name)\n\u001b[1;32m    <a href='file:///Users/levinbrinkmann/repros/algorithmic-institutions/.venv/lib/python3.9/site-packages/sklearn/utils/multiclass.py?line=332'>333</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcontinuous\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m suffix\n\u001b[0;32m--> <a href='file:///Users/levinbrinkmann/repros/algorithmic-institutions/.venv/lib/python3.9/site-packages/sklearn/utils/multiclass.py?line=334'>335</a>\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mlen\u001b[39m(np\u001b[39m.\u001b[39;49munique(y)) \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m) \u001b[39mor\u001b[39;00m (y\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m2\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(y[\u001b[39m0\u001b[39m]) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[1;32m    <a href='file:///Users/levinbrinkmann/repros/algorithmic-institutions/.venv/lib/python3.9/site-packages/sklearn/utils/multiclass.py?line=335'>336</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m suffix  \u001b[39m# [1, 2, 3] or [[1., 2., 3]] or [[1, 2]]\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/levinbrinkmann/repros/algorithmic-institutions/.venv/lib/python3.9/site-packages/sklearn/utils/multiclass.py?line=336'>337</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36munique\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/repros/algorithmic-institutions/.venv/lib/python3.9/site-packages/numpy/lib/arraysetops.py:272\u001b[0m, in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/levinbrinkmann/repros/algorithmic-institutions/.venv/lib/python3.9/site-packages/numpy/lib/arraysetops.py?line=269'>270</a>\u001b[0m ar \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masanyarray(ar)\n\u001b[1;32m    <a href='file:///Users/levinbrinkmann/repros/algorithmic-institutions/.venv/lib/python3.9/site-packages/numpy/lib/arraysetops.py?line=270'>271</a>\u001b[0m \u001b[39mif\u001b[39;00m axis \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///Users/levinbrinkmann/repros/algorithmic-institutions/.venv/lib/python3.9/site-packages/numpy/lib/arraysetops.py?line=271'>272</a>\u001b[0m     ret \u001b[39m=\u001b[39m _unique1d(ar, return_index, return_inverse, return_counts)\n\u001b[1;32m    <a href='file:///Users/levinbrinkmann/repros/algorithmic-institutions/.venv/lib/python3.9/site-packages/numpy/lib/arraysetops.py?line=272'>273</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m _unpack_tuple(ret)\n\u001b[1;32m    <a href='file:///Users/levinbrinkmann/repros/algorithmic-institutions/.venv/lib/python3.9/site-packages/numpy/lib/arraysetops.py?line=274'>275</a>\u001b[0m \u001b[39m# axis was specified and not None\u001b[39;00m\n",
      "File \u001b[0;32m~/repros/algorithmic-institutions/.venv/lib/python3.9/site-packages/numpy/lib/arraysetops.py:333\u001b[0m, in \u001b[0;36m_unique1d\u001b[0;34m(ar, return_index, return_inverse, return_counts)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/levinbrinkmann/repros/algorithmic-institutions/.venv/lib/python3.9/site-packages/numpy/lib/arraysetops.py?line=330'>331</a>\u001b[0m     aux \u001b[39m=\u001b[39m ar[perm]\n\u001b[1;32m    <a href='file:///Users/levinbrinkmann/repros/algorithmic-institutions/.venv/lib/python3.9/site-packages/numpy/lib/arraysetops.py?line=331'>332</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///Users/levinbrinkmann/repros/algorithmic-institutions/.venv/lib/python3.9/site-packages/numpy/lib/arraysetops.py?line=332'>333</a>\u001b[0m     ar\u001b[39m.\u001b[39;49msort()\n\u001b[1;32m    <a href='file:///Users/levinbrinkmann/repros/algorithmic-institutions/.venv/lib/python3.9/site-packages/numpy/lib/arraysetops.py?line=333'>334</a>\u001b[0m     aux \u001b[39m=\u001b[39m ar\n\u001b[1;32m    <a href='file:///Users/levinbrinkmann/repros/algorithmic-institutions/.venv/lib/python3.9/site-packages/numpy/lib/arraysetops.py?line=334'>335</a>\u001b[0m mask \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty(aux\u001b[39m.\u001b[39mshape, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mbool_)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "th_device = th.device(device)\n",
    "\n",
    "metrics = []\n",
    "confusion_matrix = []\n",
    "syn_pred = []\n",
    "ev = Evaluator()\n",
    "\n",
    "th_device = th.device(device)\n",
    "\n",
    "syn_index = ['prev_punishments', 'prev_contributions']\n",
    "\n",
    "def create_fully_connected(n_nodes):\n",
    "    return th.tensor([[i,j]\n",
    "        for i in range(n_nodes)\n",
    "        for j in range(n_nodes)\n",
    "    ]).T\n",
    "\n",
    "def encode(model, data, *, mask=True, index=False, x_encode=True, y_encode=True, u_encode=False, device, n_player=4):\n",
    "    data = {\n",
    "        'mask': data['valid'] if mask else None,\n",
    "        'x': model.x_encoder(**data) if x_encode else None,\n",
    "        'y_enc': model.y_encoder(**data) if y_encode else None,\n",
    "        'y': data['contributions'] if y_encode else None,\n",
    "        'u': model.u_encoder(**data) if u_encode else None,\n",
    "        'info': th.stack([data[c] for c in syn_index], dim=-1) if index else None,\n",
    "    }\n",
    "    data = {\n",
    "        k: v.to(device)\n",
    "        for k, v in data.items()\n",
    "        if v is not None\n",
    "    }\n",
    "\n",
    "    n_episodes, n_agents, n_rounds, _ = data['x'].shape\n",
    "    print(n_episodes, n_agents, n_rounds)\n",
    "\n",
    "    edge_attr = th.zeros(n_player*n_player, n_rounds,0)\n",
    "    edge_index = create_fully_connected(n_player)\n",
    "\n",
    "    n_episodes = list(data.values())[0].shape[0]\n",
    "    dataset = [\n",
    "        Data(**{k: v[i] for k, v in data.items()}, edge_attr=edge_attr, edge_index=edge_index, idx=i, group_idx=i, num_nodes=n_player)\n",
    "        for i in range(n_episodes)\n",
    "    ]\n",
    "    return dataset\n",
    "\n",
    "\n",
    "for i, (train_data, test_data) in enumerate(get_cross_validations(data, n_cross_val, fraction_training)):\n",
    "    model = AH_MODELS[model_name](\n",
    "        n_contributions=n_contributions, n_punishments=n_punishments,\n",
    "        **model_args).to(th_device)\n",
    "\n",
    "    train_data_ = encode(model, train_data, mask=True, u_encode=True, device=th_device)\n",
    "    test_data_ = encode(model, test_data, mask=True, u_encode=True, device=th_device)\n",
    "    syn_data_ = encode(model, syn_data, mask=False, y_encode=False, u_encode=True, index=True, device=th_device)\n",
    "\n",
    "    print(len(train_data_))\n",
    "\n",
    "    syn_df = using_multiindex(\n",
    "        Batch.from_data_list(syn_data_)['info'], ['idx', 'round_number'], syn_index)\n",
    "\n",
    "    ev.set_data(test=test_data_, train=train_data_, syn=syn_data_, syn_df=syn_df)\n",
    "\n",
    "    optimizer = th.optim.Adam(model.parameters(), **optimizer_args)\n",
    "    loss_fn = th.nn.CrossEntropyLoss(reduction='none')\n",
    "    sum_loss = 0\n",
    "    n_steps = 0\n",
    "\n",
    "    for e in range(train_args['epochs']):\n",
    "        ev.set_labels(cv_split=i, epoch=e)\n",
    "        model.train()\n",
    "        for j, batch_data in enumerate(iter(DataLoader(train_data_, shuffle=True, batch_size=train_args['batch_size']))):\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            py = model(batch_data).flatten(end_dim=-2)\n",
    "            y_true = batch_data['y_enc'].flatten(end_dim=-2)\n",
    "            mask = batch_data['mask'].flatten()\n",
    "            loss = loss_fn(py, y_true)\n",
    "            loss = (loss * mask).sum() / mask.sum()\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            if train_args['clamp_grad']:\n",
    "                for param in model.parameters():\n",
    "                    param.grad.data.clamp_(-train_args['clamp_grad'], train_args['clamp_grad'])\n",
    "            optimizer.step()\n",
    "            sum_loss += loss.item()\n",
    "            n_steps +=1\n",
    "        \n",
    "        if e % train_args['eval_period'] == 0:\n",
    "            avg_loss = sum_loss/n_steps\n",
    "            print(f'CV {i} | Epoch {e} | Loss {avg_loss}')\n",
    "            ev.add_loss(avg_loss)\n",
    "            ev.eval_set(model, 'train')\n",
    "            ev.eval_set(model, 'test')\n",
    "            sum_loss = 0\n",
    "            n_steps = 0\n",
    "\n",
    "    ev.eval_sync(model, syn_index=syn_index)\n",
    "\n",
    "ev.save(output_path, labels)\n",
    "model_path = os.path.join(output_path, 'model.pt')\n",
    "model.save(model_path)\n",
    "\n",
    "AH_MODELS[model_name].load(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dc1dde39",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15, 16, 1])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_data['u'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b15a4100",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60, 16, 5])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_data['x'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4c4b9ab4",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "punishments torch.Size([135, 4, 16])\n",
      "contributions torch.Size([135, 4, 16])\n",
      "valid torch.Size([135, 4, 16])\n",
      "common_good torch.Size([135, 4, 16])\n",
      "round_number torch.Size([135, 4, 16])\n",
      "is_first torch.Size([135, 4, 16])\n",
      "prev_punishments torch.Size([135, 4, 16])\n",
      "prev_contributions torch.Size([135, 4, 16])\n",
      "prev_valid torch.Size([135, 4, 16])\n",
      "prev_common_good torch.Size([135, 4, 16])\n"
     ]
    }
   ],
   "source": [
    "for k,v in train_data.items():\n",
    "    print(f\"{k} {v.shape}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b1198fd9370ee0cf82025240fa26724f68bfab1e3f74dbb4acdc06e7861d0dbe"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5.747884,
   "end_time": "2022-04-19T16:41:32.101998",
   "environment_variables": {},
   "exception": true,
   "input_path": "notebooks/artificial_humans/graph.ipynb",
   "output_path": "notebooks/artificial_humans/graph.ipynb",
   "parameters": {
    "data_file": "../../data/experiments/pilot_random1_player_round_slim.csv",
    "device": "cpu",
    "fraction_training": 1,
    "labels": {},
    "model_args": {
     "add_edge_model": false,
     "add_global_model": false,
     "add_rnn": false,
     "hidden_size": 10,
     "u_encoding": [
      {
       "etype": "float",
       "name": "prev_common_good",
       "norm": 128
      }
     ],
     "x_encoding": [
      {
       "encoding": "numeric",
       "n_levels": 21,
       "name": "prev_contributions"
      },
      {
       "encoding": "numeric",
       "n_levels": 31,
       "name": "prev_punishments"
      },
      {
       "encoding": "numeric",
       "n_levels": 16,
       "name": "round_number"
      },
      {
       "etype": "float",
       "name": "prev_common_good",
       "norm": 128
      },
      {
       "etype": "bool",
       "name": "prev_valid"
      }
     ]
    },
    "model_name": "graph",
    "n_contributions": 21,
    "n_cross_val": 2,
    "n_punishments": 31,
    "optimizer_args": {
     "lr": 0.0001,
     "weight_decay": 0.00001
    },
    "output_path": "../../data/training/dev",
    "train_args": {
     "batch_size": 20,
     "clamp_grad": 1,
     "epochs": 100,
     "eval_period": 10
    }
   },
   "start_time": "2022-04-19T16:41:26.354114",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
