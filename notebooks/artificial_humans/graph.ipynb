{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6d3f840",
   "metadata": {
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "x_encoding = [\n",
    "    {\"name\": \"prev_contributions\", \"n_levels\": 21, \"encoding\": \"numeric\"},\n",
    "    {\"name\": \"prev_punishments\", \"n_levels\": 31, \"encoding\": \"numeric\"},\n",
    "    {\"name\": \"round_number\", \"n_levels\": 16, \"encoding\": \"numeric\"},\n",
    "    {\"name\": \"prev_common_good\", \"norm\": 128, \"etype\": \"float\"},\n",
    "    {\"name\": \"prev_valid\", \"etype\": \"bool\"},\n",
    "]\n",
    "n_contributions = 21\n",
    "n_punishments = 31\n",
    "n_cross_val = 2\n",
    "fraction_training = 1.0\n",
    "data_file = \"../../data/experiments/pilot_random1_player_round_slim.csv\"\n",
    "output_path = \"../../data/training/dev\"\n",
    "labels = {}\n",
    "model_name = \"mlp\"\n",
    "model_args = {\"n_layers\": 2, \"hidden_size\": 40}\n",
    "optimizer_args = {\"lr\": 0.0001, \"weight_decay\": 1e-05}\n",
    "train_args = {\"epochs\": 1000, \"batch_size\": 40, \"clamp_grad\": 1, \"eval_period\": 10}\n",
    "device = \"cpu\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44582683",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-19T16:41:27.956497Z",
     "iopub.status.busy": "2022-04-19T16:41:27.956108Z",
     "iopub.status.idle": "2022-04-19T16:41:30.638413Z",
     "shell.execute_reply": "2022-04-19T16:41:30.637779Z"
    },
    "papermill": {
     "duration": 2.691081,
     "end_time": "2022-04-19T16:41:30.640419",
     "exception": false,
     "start_time": "2022-04-19T16:41:27.949338",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/levinbrinkmann/repros/algorithmic-institutions/.venv/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch as th\n",
    "from aimanager.generic.data import create_syn_data, create_torch_data, get_cross_validations\n",
    "from aimanager.artificial_humans import AH_MODELS\n",
    "from aimanager.artificial_humans.evaluation import Evaluator\n",
    "from aimanager.utils.array_to_df import using_multiindex\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "output_path = os.path.join(output_path, 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6659c46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-15T16:13:44.221298Z",
     "iopub.status.busy": "2022-02-15T16:13:44.220802Z",
     "iopub.status.idle": "2022-02-15T16:13:44.264216Z",
     "shell.execute_reply": "2022-02-15T16:13:44.263653Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_file)\n",
    "\n",
    "\n",
    "data = create_torch_data(df)\n",
    "syn_data = create_syn_data(n_contribution=21, n_punishment=31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f144b88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-15T16:13:44.354450Z",
     "iopub.status.busy": "2022-02-15T16:13:44.354021Z",
     "iopub.status.idle": "2022-02-15T16:14:11.080737Z",
     "shell.execute_reply": "2022-02-15T16:14:11.080147Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135\n",
      "CV 0 | Epoch 0 | Loss 3.0452667474746704\n",
      "CV 0 | Epoch 10 | Loss 3.0334501385688784\n",
      "CV 0 | Epoch 20 | Loss 3.0111855030059815\n",
      "CV 0 | Epoch 30 | Loss 2.9892133712768554\n",
      "CV 0 | Epoch 40 | Loss 2.9658118963241575\n",
      "CV 0 | Epoch 50 | Loss 2.943079912662506\n",
      "CV 0 | Epoch 60 | Loss 2.914994889497757\n",
      "CV 0 | Epoch 70 | Loss 2.890031671524048\n",
      "CV 0 | Epoch 80 | Loss 2.8635134518146517\n",
      "CV 0 | Epoch 90 | Loss 2.8340967893600464\n",
      "CV 0 | Epoch 100 | Loss 2.8059243977069857\n",
      "CV 0 | Epoch 110 | Loss 2.781332176923752\n",
      "CV 0 | Epoch 120 | Loss 2.7482638239860533\n",
      "CV 0 | Epoch 130 | Loss 2.7195549964904786\n",
      "CV 0 | Epoch 140 | Loss 2.6989544868469237\n",
      "CV 0 | Epoch 150 | Loss 2.6694578886032105\n",
      "CV 0 | Epoch 160 | Loss 2.6373047828674316\n",
      "CV 0 | Epoch 170 | Loss 2.6215018212795256\n",
      "CV 0 | Epoch 180 | Loss 2.5833326458930967\n",
      "CV 0 | Epoch 190 | Loss 2.5672889590263366\n",
      "CV 0 | Epoch 200 | Loss 2.5632621884346007\n",
      "CV 0 | Epoch 210 | Loss 2.5359054028987886\n",
      "CV 0 | Epoch 220 | Loss 2.5300695300102234\n",
      "CV 0 | Epoch 230 | Loss 2.529649090766907\n",
      "CV 0 | Epoch 240 | Loss 2.528048944473267\n",
      "CV 0 | Epoch 250 | Loss 2.5123110830783846\n",
      "CV 0 | Epoch 260 | Loss 2.5046337842941284\n",
      "CV 0 | Epoch 270 | Loss 2.5032153367996215\n",
      "CV 0 | Epoch 280 | Loss 2.4854499876499174\n",
      "CV 0 | Epoch 290 | Loss 2.498641532659531\n",
      "CV 0 | Epoch 300 | Loss 2.486119884252548\n",
      "CV 0 | Epoch 310 | Loss 2.503018230199814\n",
      "CV 0 | Epoch 320 | Loss 2.4840134620666503\n",
      "CV 0 | Epoch 330 | Loss 2.48633930683136\n",
      "CV 0 | Epoch 340 | Loss 2.485191595554352\n",
      "CV 0 | Epoch 350 | Loss 2.466847616434097\n",
      "CV 0 | Epoch 360 | Loss 2.4742377161979676\n",
      "CV 0 | Epoch 370 | Loss 2.4701898872852324\n",
      "CV 0 | Epoch 380 | Loss 2.4781714498996736\n",
      "CV 0 | Epoch 390 | Loss 2.466540938615799\n",
      "CV 0 | Epoch 400 | Loss 2.480226296186447\n",
      "CV 0 | Epoch 410 | Loss 2.4417942821979524\n",
      "CV 0 | Epoch 420 | Loss 2.4458700895309446\n",
      "CV 0 | Epoch 430 | Loss 2.449088317155838\n",
      "CV 0 | Epoch 440 | Loss 2.4385264813899994\n",
      "CV 0 | Epoch 450 | Loss 2.4472324728965758\n",
      "CV 0 | Epoch 460 | Loss 2.4369042694568632\n",
      "CV 0 | Epoch 470 | Loss 2.433235251903534\n",
      "CV 0 | Epoch 480 | Loss 2.4226567268371584\n",
      "CV 0 | Epoch 490 | Loss 2.4229590952396394\n",
      "CV 0 | Epoch 500 | Loss 2.419212633371353\n",
      "CV 0 | Epoch 510 | Loss 2.4136079132556914\n",
      "CV 0 | Epoch 520 | Loss 2.4140137910842894\n",
      "CV 0 | Epoch 530 | Loss 2.402778336405754\n",
      "CV 0 | Epoch 540 | Loss 2.4196292012929916\n",
      "CV 0 | Epoch 550 | Loss 2.4090456902980804\n",
      "CV 0 | Epoch 560 | Loss 2.3986542403697966\n",
      "CV 0 | Epoch 570 | Loss 2.4005807757377626\n",
      "CV 0 | Epoch 580 | Loss 2.399756669998169\n",
      "CV 0 | Epoch 590 | Loss 2.4044339299201964\n",
      "CV 0 | Epoch 600 | Loss 2.3846872329711912\n",
      "CV 0 | Epoch 610 | Loss 2.4050639450550078\n",
      "CV 0 | Epoch 620 | Loss 2.391512405872345\n",
      "CV 0 | Epoch 630 | Loss 2.391900449991226\n",
      "CV 0 | Epoch 640 | Loss 2.374829536676407\n",
      "CV 0 | Epoch 650 | Loss 2.379491853713989\n",
      "CV 0 | Epoch 660 | Loss 2.3781622886657714\n",
      "CV 0 | Epoch 670 | Loss 2.368464705348015\n",
      "CV 0 | Epoch 680 | Loss 2.3715674936771394\n",
      "CV 0 | Epoch 690 | Loss 2.384866291284561\n",
      "CV 0 | Epoch 700 | Loss 2.362623453140259\n",
      "CV 0 | Epoch 710 | Loss 2.352877652645111\n",
      "CV 0 | Epoch 720 | Loss 2.3588489055633546\n",
      "CV 0 | Epoch 730 | Loss 2.367889034748077\n",
      "CV 0 | Epoch 740 | Loss 2.3606094419956207\n",
      "CV 0 | Epoch 750 | Loss 2.366492933034897\n",
      "CV 0 | Epoch 760 | Loss 2.3601644158363344\n",
      "CV 0 | Epoch 770 | Loss 2.3541870057582854\n",
      "CV 0 | Epoch 780 | Loss 2.3407928884029388\n",
      "CV 0 | Epoch 790 | Loss 2.348817026615143\n",
      "CV 0 | Epoch 800 | Loss 2.337898778915405\n",
      "CV 0 | Epoch 810 | Loss 2.3270304441452025\n",
      "CV 0 | Epoch 820 | Loss 2.319853645563126\n",
      "CV 0 | Epoch 830 | Loss 2.3388624489307404\n",
      "CV 0 | Epoch 840 | Loss 2.3218763709068297\n",
      "CV 0 | Epoch 850 | Loss 2.319761353731155\n",
      "CV 0 | Epoch 860 | Loss 2.332420068979263\n",
      "CV 0 | Epoch 870 | Loss 2.32100690305233\n",
      "CV 0 | Epoch 880 | Loss 2.314007705450058\n",
      "CV 0 | Epoch 890 | Loss 2.3344783246517182\n",
      "CV 0 | Epoch 900 | Loss 2.3270662784576417\n",
      "CV 0 | Epoch 910 | Loss 2.318514484167099\n",
      "CV 0 | Epoch 920 | Loss 2.330603712797165\n",
      "CV 0 | Epoch 930 | Loss 2.332175540924072\n",
      "CV 0 | Epoch 940 | Loss 2.3045379519462585\n",
      "CV 0 | Epoch 950 | Loss 2.312056863307953\n",
      "CV 0 | Epoch 960 | Loss 2.3347620189189913\n",
      "CV 0 | Epoch 970 | Loss 2.3076055526733397\n",
      "CV 0 | Epoch 980 | Loss 2.292272982001305\n",
      "CV 0 | Epoch 990 | Loss 2.306674510240555\n",
      "135\n",
      "CV 1 | Epoch 0 | Loss 3.2056018710136414\n",
      "CV 1 | Epoch 10 | Loss 3.1767022252082824\n",
      "CV 1 | Epoch 20 | Loss 3.1358898282051086\n",
      "CV 1 | Epoch 30 | Loss 3.097258746623993\n",
      "CV 1 | Epoch 40 | Loss 3.061039686203003\n",
      "CV 1 | Epoch 50 | Loss 3.0254937767982484\n",
      "CV 1 | Epoch 60 | Loss 2.9890673995018004\n",
      "CV 1 | Epoch 70 | Loss 2.9557808101177216\n",
      "CV 1 | Epoch 80 | Loss 2.921235978603363\n",
      "CV 1 | Epoch 90 | Loss 2.8884751737117766\n",
      "CV 1 | Epoch 100 | Loss 2.8497953057289123\n",
      "CV 1 | Epoch 110 | Loss 2.820032477378845\n",
      "CV 1 | Epoch 120 | Loss 2.789930212497711\n",
      "CV 1 | Epoch 130 | Loss 2.7581080555915833\n",
      "CV 1 | Epoch 140 | Loss 2.729237234592438\n",
      "CV 1 | Epoch 150 | Loss 2.7023537397384643\n",
      "CV 1 | Epoch 160 | Loss 2.6810435175895693\n",
      "CV 1 | Epoch 170 | Loss 2.6473208367824554\n",
      "CV 1 | Epoch 180 | Loss 2.6268305480480194\n",
      "CV 1 | Epoch 190 | Loss 2.5965189754962923\n",
      "CV 1 | Epoch 200 | Loss 2.5770300388336183\n",
      "CV 1 | Epoch 210 | Loss 2.548506611585617\n",
      "CV 1 | Epoch 220 | Loss 2.5562416315078735\n",
      "CV 1 | Epoch 230 | Loss 2.526964282989502\n",
      "CV 1 | Epoch 240 | Loss 2.5083621025085447\n",
      "CV 1 | Epoch 250 | Loss 2.4994278490543365\n",
      "CV 1 | Epoch 260 | Loss 2.4962239980697634\n",
      "CV 1 | Epoch 270 | Loss 2.5025960743427276\n",
      "CV 1 | Epoch 280 | Loss 2.488170087337494\n",
      "CV 1 | Epoch 290 | Loss 2.4734019488096237\n",
      "CV 1 | Epoch 300 | Loss 2.488921755552292\n",
      "CV 1 | Epoch 310 | Loss 2.481674724817276\n",
      "CV 1 | Epoch 320 | Loss 2.462717992067337\n",
      "CV 1 | Epoch 330 | Loss 2.466766342520714\n",
      "CV 1 | Epoch 340 | Loss 2.4592423141002655\n",
      "CV 1 | Epoch 350 | Loss 2.4439923405647277\n",
      "CV 1 | Epoch 360 | Loss 2.456130492687225\n",
      "CV 1 | Epoch 370 | Loss 2.4525600492954256\n",
      "CV 1 | Epoch 380 | Loss 2.4337455332279205\n",
      "CV 1 | Epoch 390 | Loss 2.453501683473587\n",
      "CV 1 | Epoch 400 | Loss 2.4453317880630494\n",
      "CV 1 | Epoch 410 | Loss 2.4293108910322188\n",
      "CV 1 | Epoch 420 | Loss 2.427518203854561\n",
      "CV 1 | Epoch 430 | Loss 2.437261390686035\n",
      "CV 1 | Epoch 440 | Loss 2.442357224225998\n",
      "CV 1 | Epoch 450 | Loss 2.4254877865314484\n",
      "CV 1 | Epoch 460 | Loss 2.440596854686737\n",
      "CV 1 | Epoch 470 | Loss 2.4260440915822983\n",
      "CV 1 | Epoch 480 | Loss 2.421324151754379\n",
      "CV 1 | Epoch 490 | Loss 2.427455198764801\n",
      "CV 1 | Epoch 500 | Loss 2.4072331726551055\n",
      "CV 1 | Epoch 510 | Loss 2.419654530286789\n",
      "CV 1 | Epoch 520 | Loss 2.4308317840099334\n",
      "CV 1 | Epoch 530 | Loss 2.3949716210365297\n",
      "CV 1 | Epoch 540 | Loss 2.403962475061417\n",
      "CV 1 | Epoch 550 | Loss 2.4001317858695983\n",
      "CV 1 | Epoch 560 | Loss 2.410329759120941\n",
      "CV 1 | Epoch 570 | Loss 2.3885756850242617\n",
      "CV 1 | Epoch 580 | Loss 2.3948448300361633\n",
      "CV 1 | Epoch 590 | Loss 2.392269325256348\n",
      "CV 1 | Epoch 600 | Loss 2.392777091264725\n",
      "CV 1 | Epoch 610 | Loss 2.3787516355514526\n",
      "CV 1 | Epoch 620 | Loss 2.3725578814744948\n",
      "CV 1 | Epoch 630 | Loss 2.3727973997592926\n",
      "CV 1 | Epoch 640 | Loss 2.3899775445461273\n",
      "CV 1 | Epoch 650 | Loss 2.361936429142952\n",
      "CV 1 | Epoch 660 | Loss 2.3304419934749605\n",
      "CV 1 | Epoch 670 | Loss 2.377592831850052\n",
      "CV 1 | Epoch 680 | Loss 2.369074010848999\n",
      "CV 1 | Epoch 690 | Loss 2.3530305325984955\n",
      "CV 1 | Epoch 700 | Loss 2.3519542813301086\n",
      "CV 1 | Epoch 710 | Loss 2.360004311800003\n",
      "CV 1 | Epoch 720 | Loss 2.3480869948863985\n",
      "CV 1 | Epoch 730 | Loss 2.356970965862274\n",
      "CV 1 | Epoch 740 | Loss 2.339788293838501\n",
      "CV 1 | Epoch 750 | Loss 2.342839741706848\n",
      "CV 1 | Epoch 760 | Loss 2.31584438085556\n",
      "CV 1 | Epoch 770 | Loss 2.348990786075592\n",
      "CV 1 | Epoch 780 | Loss 2.3302498877048494\n",
      "CV 1 | Epoch 790 | Loss 2.3468884944915773\n",
      "CV 1 | Epoch 800 | Loss 2.32469085752964\n",
      "CV 1 | Epoch 810 | Loss 2.3413541972637177\n",
      "CV 1 | Epoch 820 | Loss 2.3089273780584336\n",
      "CV 1 | Epoch 830 | Loss 2.3323144644498823\n",
      "CV 1 | Epoch 840 | Loss 2.3232419013977053\n",
      "CV 1 | Epoch 850 | Loss 2.325436478853226\n",
      "CV 1 | Epoch 860 | Loss 2.302820146083832\n",
      "CV 1 | Epoch 870 | Loss 2.3228223741054537\n",
      "CV 1 | Epoch 880 | Loss 2.319709062576294\n",
      "CV 1 | Epoch 890 | Loss 2.32284961938858\n",
      "CV 1 | Epoch 900 | Loss 2.294121706485748\n",
      "CV 1 | Epoch 910 | Loss 2.287709304690361\n",
      "CV 1 | Epoch 920 | Loss 2.302369382977486\n",
      "CV 1 | Epoch 930 | Loss 2.30805104970932\n",
      "CV 1 | Epoch 940 | Loss 2.315122848749161\n",
      "CV 1 | Epoch 950 | Loss 2.3205133378505707\n",
      "CV 1 | Epoch 960 | Loss 2.3004174172878264\n",
      "CV 1 | Epoch 970 | Loss 2.2924194037914276\n",
      "CV 1 | Epoch 980 | Loss 2.282211658358574\n",
      "CV 1 | Epoch 990 | Loss 2.296633768081665\n"
     ]
    }
   ],
   "source": [
    "th_device = th.device(device)\n",
    "\n",
    "metrics = []\n",
    "confusion_matrix = []\n",
    "syn_pred = []\n",
    "ev = Evaluator()\n",
    "\n",
    "th_device = th.device(device)\n",
    "\n",
    "syn_index = ['prev_punishments', 'prev_contributions']\n",
    "\n",
    "def create_fully_connected(n_nodes):\n",
    "    return th.tensor([[i,j]\n",
    "        for i in range(n_nodes)\n",
    "        for j in range(n_nodes)\n",
    "    ]).T\n",
    "\n",
    "def encode(model, data, *, mask=True, index=False, x_encode=True, y_encode=True, u_encode=False, device, n_player=4):\n",
    "    data = {\n",
    "        'mask': data['valid'] if mask else None,\n",
    "        'x': model.x_encoder(**data) if x_encode else None,\n",
    "        'y_enc': model.y_encoder(**data) if y_encode else None,\n",
    "        'y': data['contributions'] if y_encode else None,\n",
    "        'u': model.u_encoder(**data) if u_encode else None,\n",
    "        'info': th.stack([data[c] for c in syn_index], dim=-1) if index else None,\n",
    "    }\n",
    "    data = {\n",
    "        k: v.to(device)\n",
    "        for k, v in data.items()\n",
    "        if v is not None\n",
    "    }\n",
    "\n",
    "    edge_attr = th.zeros(n_player*n_player,0)\n",
    "    edge_index = create_fully_connected(n_player)\n",
    "\n",
    "    n_episodes = list(data.values())[0].shape[0]\n",
    "    dataset = [\n",
    "        Data(**{k: v[i] for k, v in data.items()}, edge_attr=edge_attr, edge_index=edge_index, idx=i, group_idx=i, num_nodes=n_player)\n",
    "        for i in range(n_episodes)\n",
    "    ]\n",
    "    return dataset\n",
    "\n",
    "\n",
    "for i, (train_data, test_data) in enumerate(get_cross_validations(data, n_cross_val, fraction_training)):\n",
    "    model = AH_MODELS[model_name](\n",
    "        n_contributions=n_contributions, n_punishments=n_punishments, x_encoding=x_encoding,\n",
    "        **model_args).to(th_device)\n",
    "\n",
    "    train_data_ = encode(model, train_data, mask=True, device=th_device)\n",
    "    test_data_ = encode(model, test_data, mask=True, device=th_device)\n",
    "    syn_data_ = encode(model, syn_data, mask=False, y_encode=False, index=True, device=th_device)\n",
    "\n",
    "    print(len(train_data_))\n",
    "\n",
    "    syn_df = using_multiindex(\n",
    "        Batch.from_data_list(syn_data_)['info'], ['idx', 'round_number'], syn_index)\n",
    "\n",
    "    ev.set_data(test=test_data_, train=train_data_, syn=syn_data_, syn_df=syn_df)\n",
    "\n",
    "    optimizer = th.optim.Adam(model.parameters(), **optimizer_args)\n",
    "    loss_fn = th.nn.CrossEntropyLoss(reduction='none')\n",
    "    sum_loss = 0\n",
    "    n_steps = 0\n",
    "\n",
    "    for e in range(train_args['epochs']):\n",
    "        ev.set_labels(cv_split=i, epoch=e)\n",
    "        model.train()\n",
    "        for j, batch_data in enumerate(iter(DataLoader(train_data_, shuffle=True, batch_size=train_args['batch_size']))):\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            py = model(batch_data).flatten(end_dim=-2)\n",
    "            y_true = batch_data['y_enc'].flatten(end_dim=-2)\n",
    "            mask = batch_data['mask'].flatten()\n",
    "            loss = loss_fn(py, y_true)\n",
    "            loss = (loss * mask).sum() / mask.sum()\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            if train_args['clamp_grad']:\n",
    "                for param in model.parameters():\n",
    "                    param.grad.data.clamp_(-train_args['clamp_grad'], train_args['clamp_grad'])\n",
    "            optimizer.step()\n",
    "            sum_loss += loss.item()\n",
    "            n_steps +=1\n",
    "        \n",
    "        if e % train_args['eval_period'] == 0:\n",
    "            avg_loss = sum_loss/n_steps\n",
    "            print(f'CV {i} | Epoch {e} | Loss {avg_loss}')\n",
    "            ev.add_loss(avg_loss)\n",
    "            ev.eval_set(model, 'train')\n",
    "            ev.eval_set(model, 'test')\n",
    "            sum_loss = 0\n",
    "            n_steps = 0\n",
    "\n",
    "    ev.eval_sync(model, syn_index=syn_index)\n",
    "\n",
    "ev.save(output_path, labels)\n",
    "model_path = os.path.join(output_path, 'model.pt')\n",
    "model.save(model_path)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b1198fd9370ee0cf82025240fa26724f68bfab1e3f74dbb4acdc06e7861d0dbe"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5.747884,
   "end_time": "2022-04-19T16:41:32.101998",
   "environment_variables": {},
   "exception": true,
   "input_path": "notebooks/artificial_humans/graph.ipynb",
   "output_path": "notebooks/artificial_humans/graph.ipynb",
   "parameters": {
    "data_file": "../../data/experiments/pilot_random1_player_round_slim.csv",
    "device": "cpu",
    "fraction_training": 1,
    "labels": {},
    "model_args": {
     "hidden_size": 40,
     "n_layers": 2
    },
    "model_name": "mlp",
    "n_contributions": 21,
    "n_cross_val": 2,
    "n_punishments": 31,
    "optimizer_args": {
     "lr": 0.0001,
     "weight_decay": 0.00001
    },
    "output_path": "../../data/training/dev",
    "train_args": {
     "batch_size": 40,
     "clamp_grad": 1,
     "epochs": 1000,
     "eval_period": 10
    },
    "x_encoding": [
     {
      "encoding": "numeric",
      "n_levels": 21,
      "name": "prev_contributions"
     },
     {
      "encoding": "numeric",
      "n_levels": 31,
      "name": "prev_punishments"
     },
     {
      "encoding": "numeric",
      "n_levels": 16,
      "name": "round_number"
     },
     {
      "etype": "float",
      "name": "prev_common_good",
      "norm": 128
     },
     {
      "etype": "bool",
      "name": "prev_valid"
     }
    ]
   },
   "start_time": "2022-04-19T16:41:26.354114",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
