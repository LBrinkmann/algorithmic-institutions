{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3cb4aef8",
   "metadata": {
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "n_contributions = 21\n",
    "n_punishments = 31\n",
    "n_cross_val = 2\n",
    "fraction_training = 0.1\n",
    "data_file = \"../../data/experiments/pilot_random1_player_round_slim.csv\"\n",
    "output_path = \"../../data/training/dev\"\n",
    "labels = {}\n",
    "model_name = \"graph\"\n",
    "model_args = {\n",
    "    \"add_rnn\": False,\n",
    "    \"add_edge_model\": False,\n",
    "    \"add_global_model\": False,\n",
    "    \"hidden_size\": 10,\n",
    "    \"x_encoding\": [\n",
    "        {\"name\": \"prev_contributions\", \"n_levels\": 21, \"encoding\": \"numeric\"},\n",
    "        {\"name\": \"prev_punishments\", \"n_levels\": 31, \"encoding\": \"numeric\"},\n",
    "        {\"name\": \"round_number\", \"n_levels\": 16, \"encoding\": \"numeric\"},\n",
    "        {\"name\": \"prev_common_good\", \"norm\": 128, \"etype\": \"float\"},\n",
    "        {\"name\": \"prev_valid\", \"etype\": \"bool\"},\n",
    "    ],\n",
    "    \"u_encoding\": [{\"name\": \"prev_common_good\", \"norm\": 128, \"etype\": \"float\"}],\n",
    "}\n",
    "optimizer_args = {\"lr\": 0.001, \"weight_decay\": 1e-05}\n",
    "train_args = {\"epochs\": 1000, \"batch_size\": 20, \"clamp_grad\": 1, \"eval_period\": 10}\n",
    "shuffle_features = ['prev_punishments', 'prev_contributions', 'prev_common_good']\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "44582683",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-19T16:41:27.956497Z",
     "iopub.status.busy": "2022-04-19T16:41:27.956108Z",
     "iopub.status.idle": "2022-04-19T16:41:30.638413Z",
     "shell.execute_reply": "2022-04-19T16:41:30.637779Z"
    },
    "papermill": {
     "duration": 2.691081,
     "end_time": "2022-04-19T16:41:30.640419",
     "exception": false,
     "start_time": "2022-04-19T16:41:27.949338",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch as th\n",
    "from aimanager.generic.data import create_syn_data, create_torch_data, get_cross_validations\n",
    "from aimanager.artificial_humans import AH_MODELS\n",
    "from aimanager.artificial_humans.evaluation import Evaluator\n",
    "from aimanager.utils.array_to_df import using_multiindex\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "output_path = os.path.join(output_path, 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e6659c46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-15T16:13:44.221298Z",
     "iopub.status.busy": "2022-02-15T16:13:44.220802Z",
     "iopub.status.idle": "2022-02-15T16:13:44.264216Z",
     "shell.execute_reply": "2022-02-15T16:13:44.263653Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_file)\n",
    "\n",
    "data = create_torch_data(df)\n",
    "syn_data = create_syn_data(n_contribution=21, n_punishment=31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1f144b88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-15T16:13:44.354450Z",
     "iopub.status.busy": "2022-02-15T16:13:44.354021Z",
     "iopub.status.idle": "2022-02-15T16:14:11.080737Z",
     "shell.execute_reply": "2022-02-15T16:14:11.080147Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV 0 | Epoch 0 | Loss 2.997896194458008\n",
      "CV 0 | Epoch 10 | Loss 2.9791394472122192\n",
      "CV 0 | Epoch 20 | Loss 2.9459847450256347\n",
      "CV 0 | Epoch 30 | Loss 2.913392972946167\n",
      "CV 0 | Epoch 40 | Loss 2.8804927110671996\n",
      "CV 0 | Epoch 50 | Loss 2.8472017526626585\n",
      "CV 0 | Epoch 60 | Loss 2.8132430791854857\n",
      "CV 0 | Epoch 70 | Loss 2.7792751789093018\n",
      "CV 0 | Epoch 80 | Loss 2.7462950468063356\n",
      "CV 0 | Epoch 90 | Loss 2.715411114692688\n",
      "CV 0 | Epoch 100 | Loss 2.6875423431396483\n",
      "CV 0 | Epoch 110 | Loss 2.6635199546813966\n",
      "CV 0 | Epoch 120 | Loss 2.6437491893768312\n",
      "CV 0 | Epoch 130 | Loss 2.628084969520569\n",
      "CV 0 | Epoch 140 | Loss 2.6160059928894044\n",
      "CV 0 | Epoch 150 | Loss 2.606753873825073\n",
      "CV 0 | Epoch 160 | Loss 2.5995246171951294\n",
      "CV 0 | Epoch 170 | Loss 2.593610167503357\n",
      "CV 0 | Epoch 180 | Loss 2.588495135307312\n",
      "CV 0 | Epoch 190 | Loss 2.5838436841964723\n",
      "CV 0 | Epoch 200 | Loss 2.5794502019882204\n",
      "CV 0 | Epoch 210 | Loss 2.5751741886138917\n",
      "CV 0 | Epoch 220 | Loss 2.570928859710693\n",
      "CV 0 | Epoch 230 | Loss 2.566653919219971\n",
      "CV 0 | Epoch 240 | Loss 2.562309741973877\n",
      "CV 0 | Epoch 250 | Loss 2.557922434806824\n",
      "CV 0 | Epoch 260 | Loss 2.553393507003784\n",
      "CV 0 | Epoch 270 | Loss 2.548803687095642\n",
      "CV 0 | Epoch 280 | Loss 2.544177269935608\n",
      "CV 0 | Epoch 290 | Loss 2.5394611120224\n",
      "CV 0 | Epoch 300 | Loss 2.5346938371658325\n",
      "CV 0 | Epoch 310 | Loss 2.5298420429229735\n",
      "CV 0 | Epoch 320 | Loss 2.524891424179077\n",
      "CV 0 | Epoch 330 | Loss 2.5198450088500977\n",
      "CV 0 | Epoch 340 | Loss 2.5146903514862062\n",
      "CV 0 | Epoch 350 | Loss 2.5094453573226927\n",
      "CV 0 | Epoch 360 | Loss 2.504079008102417\n",
      "CV 0 | Epoch 370 | Loss 2.498616075515747\n",
      "CV 0 | Epoch 380 | Loss 2.49303457736969\n",
      "CV 0 | Epoch 390 | Loss 2.487265372276306\n",
      "CV 0 | Epoch 400 | Loss 2.481241321563721\n",
      "CV 0 | Epoch 410 | Loss 2.4751277685165407\n",
      "CV 0 | Epoch 420 | Loss 2.4688442945480347\n",
      "CV 0 | Epoch 430 | Loss 2.46228883266449\n",
      "CV 0 | Epoch 440 | Loss 2.4552655935287477\n",
      "CV 0 | Epoch 450 | Loss 2.4477587938308716\n",
      "CV 0 | Epoch 460 | Loss 2.4394453287124636\n",
      "CV 0 | Epoch 470 | Loss 2.4293421268463136\n",
      "CV 0 | Epoch 480 | Loss 2.41980516910553\n",
      "CV 0 | Epoch 490 | Loss 2.4106655597686766\n",
      "CV 0 | Epoch 500 | Loss 2.4016871452331543\n",
      "CV 0 | Epoch 510 | Loss 2.392929935455322\n",
      "CV 0 | Epoch 520 | Loss 2.3843671083450317\n",
      "CV 0 | Epoch 530 | Loss 2.376077938079834\n",
      "CV 0 | Epoch 540 | Loss 2.368128514289856\n",
      "CV 0 | Epoch 550 | Loss 2.360559678077698\n",
      "CV 0 | Epoch 560 | Loss 2.3534004211425783\n",
      "CV 0 | Epoch 570 | Loss 2.3466284036636353\n",
      "CV 0 | Epoch 580 | Loss 2.3402485609054566\n",
      "CV 0 | Epoch 590 | Loss 2.3342930555343626\n",
      "CV 0 | Epoch 600 | Loss 2.3287089586257936\n",
      "CV 0 | Epoch 610 | Loss 2.3234004259109495\n",
      "CV 0 | Epoch 620 | Loss 2.3183595180511474\n",
      "CV 0 | Epoch 630 | Loss 2.313674783706665\n",
      "CV 0 | Epoch 640 | Loss 2.3092733144760134\n",
      "CV 0 | Epoch 650 | Loss 2.305083417892456\n",
      "CV 0 | Epoch 660 | Loss 2.3011156558990478\n",
      "CV 0 | Epoch 670 | Loss 2.297338676452637\n",
      "CV 0 | Epoch 680 | Loss 2.293725347518921\n",
      "CV 0 | Epoch 690 | Loss 2.2902619361877443\n",
      "CV 0 | Epoch 700 | Loss 2.2869265556335447\n",
      "CV 0 | Epoch 710 | Loss 2.2837026119232178\n",
      "CV 0 | Epoch 720 | Loss 2.2805814027786253\n",
      "CV 0 | Epoch 730 | Loss 2.2775497674942016\n",
      "CV 0 | Epoch 740 | Loss 2.274596643447876\n",
      "CV 0 | Epoch 750 | Loss 2.271718430519104\n",
      "CV 0 | Epoch 760 | Loss 2.268907403945923\n",
      "CV 0 | Epoch 770 | Loss 2.266158652305603\n",
      "CV 0 | Epoch 780 | Loss 2.2634648084640503\n",
      "CV 0 | Epoch 790 | Loss 2.26082181930542\n",
      "CV 0 | Epoch 800 | Loss 2.2582242488861084\n",
      "CV 0 | Epoch 810 | Loss 2.2556856155395506\n",
      "CV 0 | Epoch 820 | Loss 2.253185534477234\n",
      "CV 0 | Epoch 830 | Loss 2.2507172584533692\n",
      "CV 0 | Epoch 840 | Loss 2.2482770681381226\n",
      "CV 0 | Epoch 850 | Loss 2.245865797996521\n",
      "CV 0 | Epoch 860 | Loss 2.243480849266052\n",
      "CV 0 | Epoch 870 | Loss 2.2411191940307615\n",
      "CV 0 | Epoch 880 | Loss 2.238768434524536\n",
      "CV 0 | Epoch 890 | Loss 2.236436867713928\n",
      "CV 0 | Epoch 900 | Loss 2.2341278791427612\n",
      "CV 0 | Epoch 910 | Loss 2.2318291664123535\n",
      "CV 0 | Epoch 920 | Loss 2.229523015022278\n",
      "CV 0 | Epoch 930 | Loss 2.227232885360718\n",
      "CV 0 | Epoch 940 | Loss 2.2249542236328126\n",
      "CV 0 | Epoch 950 | Loss 2.2226828813552855\n",
      "CV 0 | Epoch 960 | Loss 2.220414328575134\n",
      "CV 0 | Epoch 970 | Loss 2.2181649923324587\n",
      "CV 0 | Epoch 980 | Loss 2.2159369468688963\n",
      "CV 0 | Epoch 990 | Loss 2.2137211084365847\n",
      "CV 0 | Epoch 999 | Loss 2.2116248077816434\n",
      "torch.Size([272, 16, 21])\n",
      "CV 1 | Epoch 0 | Loss 3.0306365489959717\n",
      "CV 1 | Epoch 10 | Loss 2.997573804855347\n",
      "CV 1 | Epoch 20 | Loss 2.936043930053711\n",
      "CV 1 | Epoch 30 | Loss 2.871036195755005\n",
      "CV 1 | Epoch 40 | Loss 2.8011012077331543\n",
      "CV 1 | Epoch 50 | Loss 2.723956298828125\n",
      "CV 1 | Epoch 60 | Loss 2.6383647680282594\n",
      "CV 1 | Epoch 70 | Loss 2.546372389793396\n",
      "CV 1 | Epoch 80 | Loss 2.4507714748382567\n",
      "CV 1 | Epoch 90 | Loss 2.354488730430603\n",
      "CV 1 | Epoch 100 | Loss 2.260683274269104\n",
      "CV 1 | Epoch 110 | Loss 2.173154425621033\n",
      "CV 1 | Epoch 120 | Loss 2.095307970046997\n",
      "CV 1 | Epoch 130 | Loss 2.029723072052002\n",
      "CV 1 | Epoch 140 | Loss 1.9775830268859864\n",
      "CV 1 | Epoch 150 | Loss 1.9380372881889343\n",
      "CV 1 | Epoch 160 | Loss 1.9087588429450988\n",
      "CV 1 | Epoch 170 | Loss 1.8870490074157715\n",
      "CV 1 | Epoch 180 | Loss 1.870635712146759\n",
      "CV 1 | Epoch 190 | Loss 1.8578752279281616\n",
      "CV 1 | Epoch 200 | Loss 1.847637403011322\n",
      "CV 1 | Epoch 210 | Loss 1.839155662059784\n",
      "CV 1 | Epoch 220 | Loss 1.8319156050682068\n",
      "CV 1 | Epoch 230 | Loss 1.8255725622177124\n",
      "CV 1 | Epoch 240 | Loss 1.8198915600776673\n",
      "CV 1 | Epoch 250 | Loss 1.8147083520889282\n",
      "CV 1 | Epoch 260 | Loss 1.8099059820175172\n",
      "CV 1 | Epoch 270 | Loss 1.8053959131240844\n",
      "CV 1 | Epoch 280 | Loss 1.8011108875274657\n",
      "CV 1 | Epoch 290 | Loss 1.7969990611076354\n",
      "CV 1 | Epoch 300 | Loss 1.7930209040641785\n",
      "CV 1 | Epoch 310 | Loss 1.7891448378562926\n",
      "CV 1 | Epoch 320 | Loss 1.785343849658966\n",
      "CV 1 | Epoch 330 | Loss 1.7815940380096436\n",
      "CV 1 | Epoch 340 | Loss 1.7778760194778442\n",
      "CV 1 | Epoch 350 | Loss 1.7741796493530273\n",
      "CV 1 | Epoch 360 | Loss 1.770492970943451\n",
      "CV 1 | Epoch 370 | Loss 1.7668078064918518\n",
      "CV 1 | Epoch 380 | Loss 1.763109278678894\n",
      "CV 1 | Epoch 390 | Loss 1.759412372112274\n",
      "CV 1 | Epoch 400 | Loss 1.755689811706543\n",
      "CV 1 | Epoch 410 | Loss 1.7519007682800294\n",
      "CV 1 | Epoch 420 | Loss 1.7480220437049865\n",
      "CV 1 | Epoch 430 | Loss 1.7440593838691711\n",
      "CV 1 | Epoch 440 | Loss 1.7400002837181092\n",
      "CV 1 | Epoch 450 | Loss 1.7358548045158386\n",
      "CV 1 | Epoch 460 | Loss 1.7316138029098511\n",
      "CV 1 | Epoch 470 | Loss 1.7273374676704407\n",
      "CV 1 | Epoch 480 | Loss 1.7229446768760681\n",
      "CV 1 | Epoch 490 | Loss 1.718343472480774\n",
      "CV 1 | Epoch 500 | Loss 1.7136127471923828\n",
      "CV 1 | Epoch 510 | Loss 1.7088879466056823\n",
      "CV 1 | Epoch 520 | Loss 1.7041582465171814\n",
      "CV 1 | Epoch 530 | Loss 1.6994054079055787\n",
      "CV 1 | Epoch 540 | Loss 1.694629728794098\n",
      "CV 1 | Epoch 550 | Loss 1.6897775888442994\n",
      "CV 1 | Epoch 560 | Loss 1.6848040461540221\n",
      "CV 1 | Epoch 570 | Loss 1.6797213077545166\n",
      "CV 1 | Epoch 580 | Loss 1.6746089577674865\n",
      "CV 1 | Epoch 590 | Loss 1.6695228695869446\n",
      "CV 1 | Epoch 600 | Loss 1.6644373536109924\n",
      "CV 1 | Epoch 610 | Loss 1.6592453598976136\n",
      "CV 1 | Epoch 620 | Loss 1.6533053994178772\n",
      "CV 1 | Epoch 630 | Loss 1.6462438464164735\n",
      "CV 1 | Epoch 640 | Loss 1.6384528279304504\n",
      "CV 1 | Epoch 650 | Loss 1.6302219033241272\n",
      "CV 1 | Epoch 660 | Loss 1.6217788815498353\n",
      "CV 1 | Epoch 670 | Loss 1.6133485078811645\n",
      "CV 1 | Epoch 680 | Loss 1.6050925135612488\n",
      "CV 1 | Epoch 690 | Loss 1.5971073746681212\n",
      "CV 1 | Epoch 700 | Loss 1.5894389510154725\n",
      "CV 1 | Epoch 710 | Loss 1.582106363773346\n",
      "CV 1 | Epoch 720 | Loss 1.5751098155975343\n",
      "CV 1 | Epoch 730 | Loss 1.5684473514556885\n",
      "CV 1 | Epoch 740 | Loss 1.5621007800102233\n",
      "CV 1 | Epoch 750 | Loss 1.5560402870178223\n",
      "CV 1 | Epoch 760 | Loss 1.550241231918335\n",
      "CV 1 | Epoch 770 | Loss 1.5446760296821593\n",
      "CV 1 | Epoch 780 | Loss 1.539318037033081\n",
      "CV 1 | Epoch 790 | Loss 1.5341385126113891\n",
      "CV 1 | Epoch 800 | Loss 1.5291179776191712\n",
      "CV 1 | Epoch 810 | Loss 1.524232816696167\n",
      "CV 1 | Epoch 820 | Loss 1.5194666743278504\n",
      "CV 1 | Epoch 830 | Loss 1.5147651433944702\n",
      "CV 1 | Epoch 840 | Loss 1.5101006150245666\n",
      "CV 1 | Epoch 850 | Loss 1.5054975628852845\n",
      "CV 1 | Epoch 860 | Loss 1.5009483337402343\n",
      "CV 1 | Epoch 870 | Loss 1.4964614748954772\n",
      "CV 1 | Epoch 880 | Loss 1.4920533180236817\n",
      "CV 1 | Epoch 890 | Loss 1.4876875400543212\n",
      "CV 1 | Epoch 900 | Loss 1.4833704948425293\n",
      "CV 1 | Epoch 910 | Loss 1.479089081287384\n",
      "CV 1 | Epoch 920 | Loss 1.474820113182068\n",
      "CV 1 | Epoch 930 | Loss 1.4705710053443908\n",
      "CV 1 | Epoch 940 | Loss 1.4663604259490968\n",
      "CV 1 | Epoch 950 | Loss 1.4621994018554687\n",
      "CV 1 | Epoch 960 | Loss 1.4580552935600282\n",
      "CV 1 | Epoch 970 | Loss 1.4539365768432617\n",
      "CV 1 | Epoch 980 | Loss 1.449867022037506\n",
      "CV 1 | Epoch 990 | Loss 1.4458685755729674\n",
      "CV 1 | Epoch 999 | Loss 1.442149904039171\n",
      "torch.Size([268, 16, 21])\n"
     ]
    }
   ],
   "source": [
    "th_device = th.device(device)\n",
    "\n",
    "metrics = []\n",
    "confusion_matrix = []\n",
    "syn_pred = []\n",
    "ev = Evaluator()\n",
    "\n",
    "th_device = th.device(device)\n",
    "\n",
    "syn_index = ['prev_punishments', 'prev_contributions']\n",
    "\n",
    "def create_fully_connected(n_nodes):\n",
    "    return th.tensor([[i,j]\n",
    "        for i in range(n_nodes)\n",
    "        for j in range(n_nodes)\n",
    "    ]).T\n",
    "\n",
    "def encode(model, data, *, mask=True, index=False, x_encode=True, y_encode=True, u_encode=False, device, n_player=4):\n",
    "    data = {\n",
    "        'mask': data['valid'] if mask else None,\n",
    "        'x': model.x_encoder(**data) if x_encode else None,\n",
    "        'y_enc': model.y_encoder(**data) if y_encode else None,\n",
    "        'y': data['contributions'] if y_encode else None,\n",
    "        'u': model.u_encoder(**data) if u_encode and hasattr(model, 'u_encoder') else None,\n",
    "        'info': th.stack([data[c] for c in syn_index], dim=-1) if index else None,\n",
    "    }\n",
    "\n",
    "    n_episodes, n_agents, n_rounds, _ = data['x'].shape\n",
    "\n",
    "    edge_attr = th.zeros(n_player*n_player, n_rounds,0)\n",
    "    edge_index = create_fully_connected(n_player)\n",
    "\n",
    "    dataset = [\n",
    "        Data(**{k: v[i] for k, v in data.items() if v is not None}, edge_attr=edge_attr, edge_index=edge_index, idx=i, group_idx=i, num_nodes=n_player).to(device)\n",
    "        for i in range(n_episodes)\n",
    "    ]\n",
    "    return dataset\n",
    "\n",
    "def shuffle_feature(data, feature_name):\n",
    "    data = {**data}\n",
    "    data[feature_name] = data[feature_name][th.randperm(len(data[feature_name]))]\n",
    "    return data\n",
    "\n",
    "for i, (train_data, test_data) in enumerate(get_cross_validations(data, n_cross_val, fraction_training)):\n",
    "    model = AH_MODELS[model_name](\n",
    "        n_contributions=n_contributions, n_punishments=n_punishments,\n",
    "        **model_args).to(th_device)\n",
    "\n",
    "    train_data_ = encode(model, train_data, mask=True, u_encode=True, device=th_device)\n",
    "    test_data_ = encode(model, test_data, mask=True, u_encode=True, device=th_device)\n",
    "    syn_data_ = encode(model, syn_data, mask=False, y_encode=False, u_encode=True, index=True, device=th_device)\n",
    "\n",
    "    syn_df = using_multiindex(\n",
    "        Batch.from_data_list(syn_data_)['info'].detach().cpu().numpy(), ['idx', 'round_number'], syn_index)\n",
    "\n",
    "    optimizer = th.optim.Adam(model.parameters(), **optimizer_args)\n",
    "    loss_fn = th.nn.CrossEntropyLoss(reduction='none')\n",
    "    sum_loss = 0\n",
    "    n_steps = 0\n",
    "\n",
    "    for e in range(train_args['epochs']):\n",
    "        ev.set_labels(cv_split=i, epoch=e)\n",
    "        model.train()\n",
    "        for j, batch_data in enumerate(iter(DataLoader(train_data_, shuffle=True, batch_size=train_args['batch_size']))):\n",
    "            optimizer.zero_grad()\n",
    "            py = model(batch_data).flatten(end_dim=-2)\n",
    "            y_true = batch_data['y_enc'].flatten(end_dim=-2)\n",
    "            mask = batch_data['mask'].flatten()\n",
    "            loss = loss_fn(py, y_true)\n",
    "            loss = (loss * mask).sum() / mask.sum()\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            if train_args['clamp_grad']:\n",
    "                for param in model.parameters():\n",
    "                    param.grad.data.clamp_(-train_args['clamp_grad'], train_args['clamp_grad'])\n",
    "            optimizer.step()\n",
    "            sum_loss += loss.item()\n",
    "            n_steps +=1\n",
    "        \n",
    "        last_epoch = e == (train_args['epochs'] - 1)\n",
    "\n",
    "        if (e % train_args['eval_period'] == 0) or last_epoch:\n",
    "            avg_loss = sum_loss/n_steps\n",
    "            print(f'CV {i} | Epoch {e} | Loss {avg_loss}')\n",
    "            ev.add_loss(avg_loss)\n",
    "\n",
    "            ev.eval_set(model, train_data_, calc_confusion=False, set='train')\n",
    "            ev.eval_set(model, test_data_, calc_confusion=last_epoch, set='test')\n",
    "            for sf in shuffle_features:\n",
    "                shuffled_data = shuffle_feature(test_data, sf)\n",
    "                shuffled_data = encode(model, shuffled_data, mask=True, u_encode=True, device=th_device)\n",
    "                ev.eval_set(model, shuffled_data, calc_confusion=False, set='test', shuffle_feature=sf)\n",
    "            sum_loss = 0\n",
    "            n_steps = 0\n",
    "    ev.eval_syn(model, syn_data_, syn_df)\n",
    "\n",
    "ev.save(output_path, labels)\n",
    "model_path = os.path.join(output_path, 'model.pt')\n",
    "model.save(model_path)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "83484b78e3eced0c1ebbaf37dd8049c2f9102f6dcade2a60a08a368fc0daac5f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5.747884,
   "end_time": "2022-04-19T16:41:32.101998",
   "environment_variables": {},
   "exception": true,
   "input_path": "notebooks/artificial_humans/graph.ipynb",
   "output_path": "notebooks/artificial_humans/graph.ipynb",
   "parameters": {
    "data_file": "../../data/experiments/pilot_random1_player_round_slim.csv",
    "device": "cpu",
    "fraction_training": 1,
    "labels": {},
    "model_args": {
     "add_edge_model": false,
     "add_global_model": false,
     "add_rnn": false,
     "hidden_size": 10,
     "u_encoding": [
      {
       "etype": "float",
       "name": "prev_common_good",
       "norm": 128
      }
     ],
     "x_encoding": [
      {
       "encoding": "numeric",
       "n_levels": 21,
       "name": "prev_contributions"
      },
      {
       "encoding": "numeric",
       "n_levels": 31,
       "name": "prev_punishments"
      },
      {
       "encoding": "numeric",
       "n_levels": 16,
       "name": "round_number"
      },
      {
       "etype": "float",
       "name": "prev_common_good",
       "norm": 128
      },
      {
       "etype": "bool",
       "name": "prev_valid"
      }
     ]
    },
    "model_name": "graph",
    "n_contributions": 21,
    "n_cross_val": 2,
    "n_punishments": 31,
    "optimizer_args": {
     "lr": 0.0001,
     "weight_decay": 0.00001
    },
    "output_path": "../../data/training/dev",
    "train_args": {
     "batch_size": 20,
     "clamp_grad": 1,
     "epochs": 100,
     "eval_period": 10
    }
   },
   "start_time": "2022-04-19T16:41:26.354114",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
