{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5afbc74d",
   "metadata": {
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "x_encoding = [\n",
    "    {\"encoding\": \"ordinal\", \"column\": \"prev_contribution\"},\n",
    "    {\"encoding\": \"ordinal\", \"column\": \"prev_punishment\"},\n",
    "]\n",
    "y_encoding = \"ordinal\"\n",
    "n_contributions = 21\n",
    "n_punishments = 31\n",
    "n_cross_val = 2\n",
    "fraction_training = 1.0\n",
    "data = \"../data/pilot1_player_round_slim.csv\"\n",
    "output_path = \"../data/dev\"\n",
    "labels = {}\n",
    "model_args = {\"n_layers\": 2, \"hidden_size\": 40}\n",
    "optimizer_args = {\"lr\": 0.0001, \"weight_decay\": 1e-05}\n",
    "train_args = {\"epochs\": 30, \"batch_size\": 40, \"clamp_grad\": 1, \"eval_period\": 10}\n",
    "device = \"cpu\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44582683",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-15T16:13:42.924460Z",
     "iopub.status.busy": "2022-02-15T16:13:42.923968Z",
     "iopub.status.idle": "2022-02-15T16:13:43.653779Z",
     "shell.execute_reply": "2022-02-15T16:13:43.651937Z"
    },
    "papermill": {
     "duration": 0.743457,
     "end_time": "2022-02-15T16:13:43.657200",
     "exception": false,
     "start_time": "2022-02-15T16:13:42.913743",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch as th\n",
    "from aimanager.model.cross_validation import split_xy, get_cross_validations, get_fraction_of_groups\n",
    "from aimanager.model.encoder import ordinal_to_int, onehot_to_int, joined_encoder, int_encode\n",
    "from aimanager.model.metrics import create_metrics, create_confusion_matrix\n",
    "from aimanager.model.synthesize_data import syn_con_pun\n",
    "from aimanager.utils.array_to_df import add_labels, using_multiindex\n",
    "from aimanager.utils.utils import make_dir\n",
    "from aimanager.model.neural.mlp import MultiLayer\n",
    "\n",
    "output_path = os.path.join(output_path, 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3669dc3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-15T16:13:43.680006Z",
     "iopub.status.busy": "2022-02-15T16:13:43.679574Z",
     "iopub.status.idle": "2022-02-15T16:13:44.192758Z",
     "shell.execute_reply": "2022-02-15T16:13:44.192157Z"
    },
    "papermill": {
     "duration": 0.526456,
     "end_time": "2022-02-15T16:13:44.196178",
     "exception": false,
     "start_time": "2022-02-15T16:13:43.669722",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(model, x_enc):\n",
    "    y_pred_logit = model(x_enc)\n",
    "    if model.y_encoding == 'ordinal':\n",
    "        y_pred_proba = th.sigmoid(y_pred_logit).detach().cpu().numpy()\n",
    "        y_pred = ordinal_to_int(y_pred_proba)\n",
    "        y_pred_proba = np.concatenate([np.ones_like(y_pred_proba[:,[0]]), y_pred_proba[:,:]], axis=1)\n",
    "    elif model.y_encoding == 'onehot': \n",
    "        y_pred_proba = th.nn.functional.softmax(y_pred_logit, dim=-1).detach().cpu().numpy()\n",
    "        y_pred = onehot_to_int(y_pred_proba)\n",
    "    elif model.y_encoding == 'numeric': \n",
    "        y_pred = th.sigmoid(y_pred_logit).detach().cpu().numpy()\n",
    "        # TODO: n_contributions is hardcoded here\n",
    "        y_pred = np.around(y_pred*21, decimals=0).astype(np.int64)\n",
    "        y_pred_proba = None\n",
    "    else:\n",
    "        raise ValueError(f'Unkown y encoding {model.y_encoding}')\n",
    "    return y_pred, y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6659c46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-15T16:13:44.221298Z",
     "iopub.status.busy": "2022-02-15T16:13:44.220802Z",
     "iopub.status.idle": "2022-02-15T16:13:44.264216Z",
     "shell.execute_reply": "2022-02-15T16:13:44.263653Z"
    },
    "papermill": {
     "duration": 0.057011,
     "end_time": "2022-02-15T16:13:44.267525",
     "exception": false,
     "start_time": "2022-02-15T16:13:44.210514",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(data)\n",
    "\n",
    "df['contribution'] = pd.Categorical(\n",
    "    df['contribution'], categories=np.arange(n_contributions), ordered=True\n",
    ")\n",
    "df['punishment'] = pd.Categorical(\n",
    "    df['punishment'], categories=np.arange(n_punishments), ordered=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "825924ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-15T16:13:44.293187Z",
     "iopub.status.busy": "2022-02-15T16:13:44.292690Z",
     "iopub.status.idle": "2022-02-15T16:13:44.327833Z",
     "shell.execute_reply": "2022-02-15T16:13:44.327271Z"
    },
    "papermill": {
     "duration": 0.048849,
     "end_time": "2022-02-15T16:13:44.331260",
     "exception": false,
     "start_time": "2022-02-15T16:13:44.282411",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Evaluator:\n",
    "    def __init__(self):\n",
    "        self.metrics = []\n",
    "        self.confusion_matrix = []\n",
    "        self.synthetic_predicitions = []\n",
    "\n",
    "    def set_data(self,data):\n",
    "        self.data = data\n",
    "\n",
    "    def set_labels(self, **labels):\n",
    "        self.labels = labels\n",
    "\n",
    "    def eval_set(self, model, set_name):\n",
    "        model.eval()\n",
    "        y_pred, y_pred_proba = predict(model, self.data['x_enc'][set_name])\n",
    "        self.metrics += create_metrics(self.data['y_sr'][set_name], y_pred, set=set_name, **self.labels)\n",
    "        self.confusion_matrix += create_confusion_matrix(\n",
    "            self.data['y_sr'][set_name], y_pred, set=set_name, **self.labels)\n",
    "\n",
    "    def eval_sync(self, model):\n",
    "        model.eval()\n",
    "        pred_df = self.data['x_df']['syn'].copy()\n",
    "        y_pred, y_pred_proba = predict(model, self.data['x_enc']['syn'])\n",
    "        if y_pred_proba is not None:\n",
    "            pred_df['contribution_pred'] = y_pred\n",
    "            proba_df = using_multiindex(y_pred_proba, ['sample_idx', 'contribution']).rename(columns={'value': 'proba'})\n",
    "            pred_df =  pred_df.merge(proba_df)\n",
    "            pred_df['predicted'] = pred_df['contribution_pred'] == pred_df['contribution']\n",
    "            pred_df = pred_df.drop(columns = ['contribution_pred'])\n",
    "        else:\n",
    "            pred_df['contribution'] = y_pred\n",
    "            pred_df['predicted'] = True\n",
    "        pred_df = add_labels(pred_df, {'set': 'train', 'cv_split': i})\n",
    "        self.synthetic_predicitions += pred_df.to_dict('records')\n",
    "\n",
    "    def add_loss(self, loss):\n",
    "        self.metrics.append(dict(name='loss', value=loss, **self.labels))\n",
    "\n",
    "    def save(self, output_path, labels):\n",
    "        make_dir(output_path)\n",
    "        self._save_metric(self.metrics, 'metrics.parquet', output_path, labels)\n",
    "        self._save_metric(self.confusion_matrix, 'confusion_matrix.parquet', output_path, labels)\n",
    "        self._save_metric(self.synthetic_predicitions, 'synthetic_predicitions.parquet', output_path, labels)\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def _save_metric(rec, filename, output_path, labels):\n",
    "        df = pd.DataFrame(rec)\n",
    "        df = add_labels(df, labels)\n",
    "        df.to_parquet(os.path.join(output_path, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f144b88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-15T16:13:44.354450Z",
     "iopub.status.busy": "2022-02-15T16:13:44.354021Z",
     "iopub.status.idle": "2022-02-15T16:14:11.080737Z",
     "shell.execute_reply": "2022-02-15T16:14:11.080147Z"
    },
    "papermill": {
     "duration": 26.739528,
     "end_time": "2022-02-15T16:14:11.084012",
     "exception": false,
     "start_time": "2022-02-15T16:13:44.344484",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mpib/brinkmann/repros/algorithmic-institutions/.venv/lib/python3.9/site-packages/torch/autograd/__init__.py:154: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 10010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:112.)\n",
      "  Variable._execution_engine.run_backward(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV 0 | Epoch 0 | Loss 0.6886756139643052\n",
      "CV 0 | Epoch 10 | Loss 0.5954662143307574\n",
      "CV 0 | Epoch 20 | Loss 0.46376721942249466\n",
      "CV 1 | Epoch 0 | Loss 0.6944719307562884\n",
      "CV 1 | Epoch 10 | Loss 0.5917453217155794\n",
      "CV 1 | Epoch 20 | Loss 0.45243263588670424\n"
     ]
    }
   ],
   "source": [
    "th_device = th.device(device)\n",
    "\n",
    "metrics = []\n",
    "confusion_matrix = []\n",
    "syn_pred = []\n",
    "ev = Evaluator()\n",
    "\n",
    "x_df, y_sr = split_xy(df)\n",
    "for i, split in enumerate(get_cross_validations(x_df, y_sr, n_cross_val)):\n",
    "    x_train_df, y_train_sr, x_test_df, y_test_sr = split\n",
    "    x_train_df, y_train_sr = get_fraction_of_groups(x_train_df, y_train_sr, fraction_training)\n",
    "    x_syn_df = syn_con_pun(n_contributions, n_punishments)\n",
    "    data = {\n",
    "        'x_df': {'train': x_train_df, 'syn': x_syn_df, 'test': x_test_df },\n",
    "        'y_sr': {'train': y_train_sr, 'test': y_test_sr }}\n",
    "    data['x_enc'] = {\n",
    "        k: th.tensor(joined_encoder(x, x_encoding), dtype=th.float, device=th_device)\n",
    "        for  k, x in data['x_df'].items()\n",
    "    }\n",
    "    data['y_enc'] = {\n",
    "        k: th.tensor(\n",
    "            int_encode(y, encoding=y_encoding, add_axis=False),\n",
    "            dtype=th.float, device=th_device)\n",
    "        for  k, y in data['y_sr'].items()\n",
    "    }\n",
    "    ev.set_data(data)\n",
    "\n",
    "    if y_encoding == 'ordinal':\n",
    "        output_size = (n_contributions - 1)\n",
    "    elif y_encoding == 'onehot':\n",
    "        output_size = n_contributions\n",
    "    elif y_encoding == 'numeric':\n",
    "        output_size = 1\n",
    "    else:\n",
    "        raise ValueError(f'Unkown y encoding {y_encoding}')\n",
    "    \n",
    "    model = MultiLayer(\n",
    "        input_size=data['x_enc']['train'].shape[1], output_size=output_size, **model_args).to(th_device)\n",
    "    model.y_encoding = y_encoding\n",
    "    optimizer = th.optim.Adam(model.parameters(), **optimizer_args)\n",
    "\n",
    "    if y_encoding == 'ordinal':\n",
    "        loss_fn = th.nn.BCEWithLogitsLoss()\n",
    "    elif y_encoding == 'onehot':\n",
    "        loss_fn = th.nn.CrossEntropyLoss()\n",
    "    elif y_encoding == 'numeric':\n",
    "        mse = th.nn.MSELoss()\n",
    "        sig = th.nn.Sigmoid()\n",
    "        def _loss_fn(yhat,y):\n",
    "            yhat = sig(yhat)*n_contributions\n",
    "            return mse(yhat[:,0],y)\n",
    "        loss_fn = _loss_fn\n",
    "\n",
    "    sum_loss = 0\n",
    "    n_steps = 0\n",
    "    batch_size = train_args['batch_size']\n",
    "\n",
    "    for e in range(train_args['epochs']):\n",
    "        ev.set_labels(cv_split=i, epoch=e)\n",
    "        model.train()\n",
    "        for start_idx in range(0, len(data['x_enc']['train']), batch_size):\n",
    "            tx = data['x_enc']['train'][start_idx:start_idx+batch_size]\n",
    "            ty = data['y_enc']['train'][start_idx:start_idx+batch_size]\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            py = model(tx)\n",
    "            loss = loss_fn(py, ty)\n",
    "            loss.backward()\n",
    "\n",
    "            if train_args['clamp_grad']:\n",
    "                for param in model.parameters():\n",
    "                    param.grad.data.clamp_(-train_args['clamp_grad'], train_args['clamp_grad'])\n",
    "            optimizer.step()\n",
    "            sum_loss += loss.item()\n",
    "            n_steps +=1\n",
    "        \n",
    "        if e % train_args['eval_period'] == 0:\n",
    "            avg_loss = sum_loss/n_steps\n",
    "            print(f'CV {i} | Epoch {e} | Loss {avg_loss}')\n",
    "            ev.add_loss(avg_loss)\n",
    "            ev.eval_set(model, 'train')\n",
    "            ev.eval_set(model, 'test')\n",
    "            sum_loss = 0\n",
    "            n_steps = 0\n",
    "\n",
    "    ev.eval_sync(model)\n",
    "\n",
    "ev.save(output_path, labels)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b1198fd9370ee0cf82025240fa26724f68bfab1e3f74dbb4acdc06e7861d0dbe"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 30.003052,
   "end_time": "2022-02-15T16:14:11.718838",
   "environment_variables": {},
   "exception": null,
   "input_path": "neural.ipynb",
   "output_path": "neural.ipynb",
   "parameters": {
    "data": "../data/pilot1_player_round_slim.csv",
    "device": "cpu",
    "fraction_training": 1,
    "labels": {},
    "model_args": {
     "hidden_size": 40,
     "n_layers": 2
    },
    "n_contributions": 21,
    "n_cross_val": 2,
    "n_punishments": 31,
    "optimizer_args": {
     "lr": 0.0001,
     "weight_decay": 0.00001
    },
    "output_path": "../data/dev",
    "train_args": {
     "batch_size": 40,
     "clamp_grad": 1,
     "epochs": 100,
     "eval_period": 10
    },
    "x_encoding": [
     {
      "column": "prev_contribution",
      "encoding": "ordinal"
     },
     {
      "column": "prev_punishment",
      "encoding": "ordinal"
     }
    ],
    "y_encoding": "numeric"
   },
   "start_time": "2022-02-15T16:13:41.715786",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
